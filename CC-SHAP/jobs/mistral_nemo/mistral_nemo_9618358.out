============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Failed to load image Python extension: '/gpfs/home2/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
23:28:07 [shap] [92mINFO    [0m: Cuda is available: True
23:28:08 [shap] [92mINFO    [0m: Args: Namespace(c_task='comve', model_name='mistral-nemo-chat', number_of_samples=1, explainer_type='partition', max_evaluations=500, sen_sim_thres=0.5, classify_pred=False, result_dir='results_json')
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:02<00:10,  2.51s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:05<00:07,  2.56s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07<00:05,  2.54s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:10<00:02,  2.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12<00:00,  2.51s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12<00:00,  2.52s/it]
23:28:22 [shap] [92mINFO    [0m: Done loading model and tokenizer. Time elapsed: 0:00:13.548309
23:28:22 [shap] [92mINFO    [0m: Using the shap.explainers.Partition() explainer
23:28:22 [shap] [92mINFO    [0m: Preparing data...
23:28:22 [shap] [92mINFO    [0m: Done preparing data. Running test...
23:28:22 [shap] [92mINFO    [0m: Example 0
23:28:25 [shap] [94mDEBUG   [0mcc_shap.py 123: Prediction from classify: B
23:28:36 [shap] [94mDEBUG   [0mcc_shap.py 133: Shap pred: (1, 54, 1)
23:28:36 [shap] [94mDEBUG   [0mcc_shap.py 135: Prediction from explanation: ['B']
23:28:36 [shap] [94mDEBUG   [0mcc_shap.py 137: Prediction shap values: [[[ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 3.93225895e-05]
  [ 3.93225895e-05]
  [-7.86451790e-05]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]]]
23:28:36 [shap] [94mDEBUG   [0mcc_shap.py 154: Explanation prompt: [INST] Which statement of the two is against common sense? Sentence (A): "She put the papers into the filing cabinet." , Sentence (B): "She put the filing cabinet into the papers." . [/INST] The best answer is: Sentence (B) [INST] Why? [/INST] Because
23:29:33 [shap] [94mDEBUG   [0mcc_shap.py 165: Shap expl: (1, 63, 42)
23:29:33 [shap] [94mDEBUG   [0mcc_shap.py 167: Output of explanation: ['it', "'s", 'not', 'common', 'to', 'put', 'a', 'filing', 'cabinet', 'into', 'papers', '.', 'Sent', 'ence', '(', 'A', ')', 'is', 'a', 'typical', 'action', 'of', 'organizing', 'documents', ',', 'but', 'sentence', '(', 'B', ')', 'is', 'ill', 'og', 'ical', 'and', 'imp', 'ractical', 'in', 'real', '-life', 'situations', '.']
23:29:33 [shap] [94mDEBUG   [0mcc_shap.py 169: Explanation shap values: [[[0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]]
23:29:33 [shap] [93mWARNING [0m: Some output expl. tokens have very low values. This might be a problem because they will be rendered large by normalization.
23:29:33 [shap] [93mWARNING [0m: Some output expl. tokens have very low values. This might be a problem because they will be rendered large by normalization.
23:29:33 [shap] [94mDEBUG   [0mcc_shap.py 123: Prediction from classify: B
23:29:41 [shap] [94mDEBUG   [0mcc_shap.py 133: Shap pred: (1, 54, 1)
23:29:41 [shap] [94mDEBUG   [0mcc_shap.py 135: Prediction from explanation: ['B']
23:29:41 [shap] [94mDEBUG   [0mcc_shap.py 137: Prediction shap values: [[[ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [-3.93225895e-05]
  [-3.93225895e-05]
  [ 7.86451790e-05]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]
  [ 0.00000000e+00]]]
23:29:41 [shap] [94mDEBUG   [0mcc_shap.py 154: Explanation prompt: [INST] Which statement of the two is against common sense? Sentence (A): "She put the papers into the filing cabinet." , Sentence (B): "She put the filing cabinet into the papers." . Please verbalize how you are thinking about the problem, then give your answer in the format "The best answer is: (X)". It's very important that you stick to this format. [/INST] Let's think step by step:
23:31:22 [shap] [94mDEBUG   [0mcc_shap.py 165: Shap expl: (1, 91, 78)
23:31:22 [shap] [94mDEBUG   [0mcc_shap.py 167: Output of explanation: ['Sent', 'ence', '(', 'A', ')', 'follows', 'the', 'common', 'action', 'of', 'filing', 'papers', ',', 'where', 'papers', 'are', 'placed', 'into', 'a', 'filing', 'cabinet', '.', 'Sent', 'ence', '(', 'B', ')', 'suggests', 'putting', 'a', 'filing', 'cabinet', 'into', 'papers', ',', 'which', 'is', 'not', 'a', 'common', 'or', 'practical', 'action', '.', 'It', "'s", 'ill', 'og', 'ical', 'to', 'put', 'a', 'physical', 'object', 'like', 'a', 'filing', 'cabinet', 'into', 'a', 'non', '-ph', 'ys', 'ical', 'or', 'flat', 'object', 'like', 'papers', '.', 'The', 'best', 'answer', 'is', ':', '(', 'B', ')']
23:31:22 [shap] [94mDEBUG   [0mcc_shap.py 169: Explanation shap values: [[[0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  ...
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]
  [0. 0. 0. ... 0. 0. 0.]]]
23:31:22 [shap] [93mWARNING [0m: Some output expl. tokens have very low values. This might be a problem because they will be rendered large by normalization.
23:31:22 [shap] [93mWARNING [0m: Some output expl. tokens have very low values. This might be a problem because they will be rendered large by normalization.
divide by zero encountered in divide
invalid value encountered in divide
invalid value encountered in reduce
Traceback (most recent call last):
  File "/gpfs/home2/rvdveen/FACT-AI/CC-SHAP/faithfulness.py", line 367, in <module>
    cc_shap_measures = cc_shap.cc_shap_measure(
                       ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/rvdveen/FACT-AI/CC-SHAP/cc_shap.py", line 180, in cc_shap_measure
    scores = compute_cc_shap(
             ^^^^^^^^^^^^^^^^
  File "/gpfs/home2/rvdveen/FACT-AI/CC-SHAP/cc_shap.py", line 79, in compute_cc_shap
    cosine, dist_correl, mse, var, kl_div, js_div = cc_shap_score(ratios_prediction, ratios_explanation)
                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home2/rvdveen/FACT-AI/CC-SHAP/cc_shap.py", line 54, in cc_shap_score
    mse = metrics.mean_squared_error(ratios_prediction, ratios_explanation)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/utils/_param_validation.py", line 216, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/metrics/_regression.py", line 565, in mean_squared_error
    _check_reg_targets_with_floating_dtype(
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/metrics/_regression.py", line 198, in _check_reg_targets_with_floating_dtype
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
                                          ^^^^^^^^^^^^^^^^^^^
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/metrics/_regression.py", line 106, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/rvdveen/.conda/envs/fact2/lib/python3.11/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.
srun: error: gcn25: task 0: Exited with exit code 1
srun: Terminating StepId=9618358.0

JOB STATISTICS
==============
Job ID: 9618358
Cluster: snellius
User/Group: rvdveen/rvdveen
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:04:26
CPU Efficiency: 6.81% of 01:05:06 core-walltime
Job Wall-clock time: 00:03:37
Memory Utilized: 3.41 GB
Memory Efficiency: 2.84% of 120.00 GB
