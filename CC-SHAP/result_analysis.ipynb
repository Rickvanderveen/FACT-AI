{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON file and return its contents as a dictionary.\n",
    "\n",
    "    :param file_path: Path to the JSON file.\n",
    "    :return: Parsed JSON content as a dictionary.\n",
    "    :raises: FileNotFoundError, json.JSONDecodeError\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Failed to decode JSON from file '{file_path}'.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResult:\n",
    "    def __init__(self, results_json):\n",
    "        self.results_json = results_json\n",
    "    \n",
    "    @property\n",
    "    def args(self):\n",
    "        return self.results_json[\"args\"]\n",
    "    \n",
    "    @property\n",
    "    def model(self) -> dict:\n",
    "        return self.results_json[\"model\"]\n",
    "    \n",
    "    @property\n",
    "    def examples(self) -> dict:\n",
    "        return self.results_json[\"samples\"]\n",
    "    \n",
    "    @property\n",
    "    def explainer(self) -> str:\n",
    "        return self.results_json[\"explainer\"]\n",
    "    \n",
    "    @property\n",
    "    def tests(self) -> list[str]:\n",
    "        return self.results_json[\"tests\"]\n",
    "    \n",
    "    @property\n",
    "    def time_elapsed(self) -> str:\n",
    "        since_epoch = datetime.datetime.strptime(self.results_json[\"time_elapsed\"], \"%H:%M:%S.%f\")\n",
    "        time_elapsed = datetime.timedelta(\n",
    "            hours=since_epoch.hour,\n",
    "            minutes=since_epoch.minute,\n",
    "            seconds=since_epoch.second,\n",
    "            microseconds=since_epoch.microsecond\n",
    "        )\n",
    "        return time_elapsed\n",
    "    \n",
    "    def __repr__(self):\n",
    "        model = f\"Model: {self.model[\"full_model_name\"]} ({self.model[\"dtype\"]})\"\n",
    "        tests = f\"Tests: {self.tests}\"\n",
    "        explainer = f\"Explainer: {self.explainer})\"\n",
    "        examples = f\"Examples: {len(self.examples)}\"\n",
    "        args = f\"Args: {self.args}\"\n",
    "        time_elapsed = f\"Time elapsed: {self.time_elapsed}\"\n",
    "\n",
    "        return \"\\n\".join((model, tests, explainer, examples, args, time_elapsed))\n",
    "\n",
    "    def examples_names(self) -> list[str]:\n",
    "        return list(self.examples.keys())\n",
    "\n",
    "    def get_example(self, example_name: str) -> dict:\n",
    "        return self.examples[example_name]\n",
    "    \n",
    "    def get_variable(self, variable):\n",
    "        cc_shap_cot_values = []\n",
    "        for example_name in self.examples_names():\n",
    "            cc_shap_score = self.get_example(example_name)[variable]\n",
    "            cc_shap_cot_values.append(float(cc_shap_score))\n",
    "\n",
    "        return np.array(cc_shap_cot_values)\n",
    "\n",
    "    def describe(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "\n",
    "        print(\"Mean: \", variable_values.mean())\n",
    "        print(\"Min: \", variable_values.min())\n",
    "        print(\"Max: \", variable_values.max())\n",
    "        print(\"Std dev: \", variable_values.std())\n",
    "    \n",
    "    def mean(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "        return variable_values.mean()\n",
    "\n",
    "    def boxplot(self, variable):\n",
    "        cc_shap_cot_values = self.get_variable(variable)\n",
    "\n",
    "        plt.boxplot(cc_shap_cot_values, orientation=\"horizontal\")\n",
    "        plt.xlim((-1.0, 1.0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResults:\n",
    "    def __init__(self, result_files: list[Path]):\n",
    "        self.result_files = result_files\n",
    "    \n",
    "    def load(self):\n",
    "        for file in self.result_files:\n",
    "            result_json = load_json_file(file)\n",
    "            yield ExperimentResult(result_json)\n",
    "    \n",
    "    def compare(self, variable, metric):\n",
    "        variable_values = []\n",
    "        for idx, result_file in enumerate(self.result_files):\n",
    "            result_json = load_json_file(result_file)\n",
    "            variable_value = ExperimentResult(result_json).get_variable(variable)\n",
    "            metric_value = metric(variable_value)\n",
    "            variable_values.append(metric_value)\n",
    "        return variable_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = Path(\"results_json\")\n",
    "\n",
    "COMVE = \"comve\"\n",
    "ESNLI = \"esnli\"\n",
    "DQA = \"disambiguation_qa\"\n",
    "\n",
    "LLAMA2 = \"llama2-7b-chat\"\n",
    "FALCON = \"falcon-7b-chat\"\n",
    "FALCON3 = \"falcon3-7B-chat\"\n",
    "\n",
    "EXPLAINER = \"partition\"\n",
    "\n",
    "comve_llama2 = result_dir / f\"{COMVE}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "esnli_llama2 = result_dir / f\"{ESNLI}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "dqa_llama2 = result_dir / f\"{DQA}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon = result_dir / f\"{COMVE}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "esnli_falcon = result_dir / f\"{ESNLI}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "dqa_falcon = result_dir / f\"{DQA}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon3 = result_dir / f\"{COMVE}_{FALCON3}_{100}_{EXPLAINER}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative: [ 1.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.\n",
      "  5.  5.  5.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  7.  8.  8.  9.  9.\n",
      "  9.  9. 10. 11. 11. 11. 11. 11. 12. 12. 12. 12. 13. 14. 14. 14. 14. 14.\n",
      " 14. 15. 15. 15. 15. 16. 16. 16. 16. 17. 17. 17. 18. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 20. 21. 21. 21. 21. 21. 21. 22. 22.\n",
      " 22. 22. 22. 22. 23. 23. 23. 23. 23. 23.] \n",
      "\n",
      "Differences: [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Transforms a cumulative array to a array of differences\n",
    "def cumsum_to_differences(cumsum_array):\n",
    "    return np.array([\n",
    "        cumsum_array[idx] - cumsum_array[idx - 1]\n",
    "        if idx != 0 else cumsum_array[idx]\n",
    "        for idx, _ in enumerate(cumsum_array)\n",
    "    ])\n",
    "\n",
    "in_expl_cumsum = ExperimentResult(\n",
    "    load_json_file(comve_llama2)\n",
    ").get_variable(\"atanasova_input_from_expl\")\n",
    "print(\"Cumulative:\", in_expl_cumsum, \"\\n\")\n",
    "print(\"Differences:\", cumsum_to_differences(in_expl_cumsum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: tiiuae/Falcon3-7B-Instruct (torch.float16)\n",
      "Tests: ['atanasova_counterfactual', 'atanasova_input_from_expl', 'cc_shap-posthoc', 'turpin', 'cc_shap-cot']\n",
      "Explainer: {'type': 'shap.explainers.Partition()', 'max_evaluations': 500})\n",
      "Examples: 100\n",
      "Args: Namespace(c_task='comve', model_name='falcon3-7B-chat', number_of_samples=100, explainer_type='partition', max_evaluations=500, classify_pred=False)\n",
      "Time elapsed: 4:59:40.848789\n"
     ]
    }
   ],
   "source": [
    "print(ExperimentResult(load_json_file(comve_falcon3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_arg(input_str, arg_name) -> str | None:\n",
    "    pattern = rf\"{arg_name}=(?:'([^']*)'|(\\d+))\"\n",
    "    match = re.search(pattern, input_str)\n",
    "    if match:\n",
    "        return match.group(1) or int(match.group(2))\n",
    "    return None\n",
    "\n",
    "experiments = [\n",
    "    comve_llama2,\n",
    "    esnli_llama2,\n",
    "    dqa_llama2,\n",
    "    comve_falcon,\n",
    "    esnli_falcon,\n",
    "    dqa_falcon,\n",
    "    comve_falcon3,\n",
    "]\n",
    "\n",
    "TEST_TO_VARIABLE_NAME = {\n",
    "    \"atanasova_counterfactual\": \"atanasova_counterfact\",\n",
    "    \"atanasova_input_from_expl\": \"atanasova_input_from_expl\",\n",
    "    \"cc_shap-posthoc\": \"cc_shap-posthoc\",\n",
    "    \"turpin\": \"turpin\",\n",
    "    \"cc_shap-cot\": \"cc_shap-cot\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for experiment in experiments:\n",
    "    experiment = ExperimentResult(load_json_file(experiment))\n",
    "    args = experiment.args\n",
    "    short_model_name = find_arg(args, \"model_name\")\n",
    "    dataset = find_arg(args, \"c_task\")\n",
    "    n_samples = find_arg(args, \"number_of_samples\")\n",
    "\n",
    "    assert n_samples == len(experiment.examples_names()), \"Number of samples from args is different than actual number of samples\"\n",
    "\n",
    "    for test in experiment.tests:\n",
    "        variable_name = TEST_TO_VARIABLE_NAME[test]\n",
    "        test_results = experiment.get_variable(variable_name)\n",
    "\n",
    "        # The \"atanasova_input_from_expl\" keeps a counter and not 0 or 1\n",
    "        # per sample\n",
    "        if test == \"atanasova_input_from_expl\":\n",
    "            test_results = cumsum_to_differences(test_results)\n",
    "\n",
    "        mean = np.mean(test_results)\n",
    "        std = np.std(test_results)\n",
    "        min_val = np.min(test_results)\n",
    "        max_val = np.max(test_results)\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": short_model_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_samples\": n_samples,\n",
    "            \"test\": test,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "\n",
    "experimentsresults_dataframe = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>test</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>-0.0243</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.126175</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.121106</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.200265</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.191141</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.113236</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.493559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1663</td>\n",
       "      <td>0.192331</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.089853</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.088299</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model            dataset  n_samples                       test  \\\n",
       "0    llama2-7b-chat              comve        100   atanasova_counterfactual   \n",
       "1    llama2-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "2    llama2-7b-chat              comve        100            cc_shap-posthoc   \n",
       "3    llama2-7b-chat              comve        100                     turpin   \n",
       "4    llama2-7b-chat              comve        100                cc_shap-cot   \n",
       "5    llama2-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "6    llama2-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "7    llama2-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "8    llama2-7b-chat              esnli        100                     turpin   \n",
       "9    llama2-7b-chat              esnli        100                cc_shap-cot   \n",
       "10   llama2-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "11   llama2-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "12   llama2-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "13   llama2-7b-chat  disambiguation_qa        100                     turpin   \n",
       "14   llama2-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "15   falcon-7b-chat              comve        100   atanasova_counterfactual   \n",
       "16   falcon-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "17   falcon-7b-chat              comve        100            cc_shap-posthoc   \n",
       "18   falcon-7b-chat              comve        100                     turpin   \n",
       "19   falcon-7b-chat              comve        100                cc_shap-cot   \n",
       "20   falcon-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "21   falcon-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "22   falcon-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "23   falcon-7b-chat              esnli        100                     turpin   \n",
       "24   falcon-7b-chat              esnli        100                cc_shap-cot   \n",
       "25   falcon-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "26   falcon-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "27   falcon-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "28   falcon-7b-chat  disambiguation_qa        100                     turpin   \n",
       "29   falcon-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "30  falcon3-7B-chat              comve        100   atanasova_counterfactual   \n",
       "31  falcon3-7B-chat              comve        100  atanasova_input_from_expl   \n",
       "32  falcon3-7B-chat              comve        100            cc_shap-posthoc   \n",
       "33  falcon3-7B-chat              comve        100                     turpin   \n",
       "34  falcon3-7B-chat              comve        100                cc_shap-cot   \n",
       "\n",
       "      mean       std   min   max  \n",
       "0   0.8600  0.346987  0.00  1.00  \n",
       "1   0.2300  0.420833  0.00  1.00  \n",
       "2  -0.0243  0.105245 -0.24  0.37  \n",
       "3   0.6000  0.489898  0.00  1.00  \n",
       "4  -0.1027  0.106910 -0.35  0.33  \n",
       "5   0.5200  0.499600  0.00  1.00  \n",
       "6   0.0000  0.000000  0.00  0.00  \n",
       "7   0.1241  0.126175 -0.17  0.39  \n",
       "8   0.3100  0.462493  0.00  1.00  \n",
       "9   0.0812  0.121106 -0.24  0.34  \n",
       "10  0.7600  0.427083  0.00  1.00  \n",
       "11  0.0000  0.000000  0.00  0.00  \n",
       "12  0.0800  0.200265 -0.32  0.52  \n",
       "13  0.3800  0.485386  0.00  1.00  \n",
       "14  0.0605  0.191141 -0.43  0.62  \n",
       "15  0.2300  0.420833  0.00  1.00  \n",
       "16  0.0000  0.000000  0.00  0.00  \n",
       "17  0.1232  0.082667 -0.06  0.33  \n",
       "18  0.5700  0.495076  0.00  1.00  \n",
       "19  0.0436  0.102747 -0.33  0.53  \n",
       "20  0.3100  0.462493  0.00  1.00  \n",
       "21  0.0000  0.000000  0.00  0.00  \n",
       "22  0.1642  0.079501 -0.02  0.43  \n",
       "23  0.0800  0.271293  0.00  1.00  \n",
       "24  0.0658  0.113236 -0.27  0.28  \n",
       "25  0.4200  0.493559  0.00  1.00  \n",
       "26  0.0000  0.000000  0.00  0.00  \n",
       "27  0.0821  0.094491 -0.16  0.36  \n",
       "28  0.4000  0.489898  0.00  1.00  \n",
       "29 -0.1663  0.192331 -0.47  0.51  \n",
       "30  0.8500  0.357071  0.00  1.00  \n",
       "31  0.4900  0.499900  0.00  1.00  \n",
       "32  0.3462  0.089853  0.15  0.62  \n",
       "33  0.9100  0.286182  0.00  1.00  \n",
       "34  0.5085  0.088299  0.29  0.77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experimentsresults_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
