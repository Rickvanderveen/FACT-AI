{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON file and return its contents as a dictionary.\n",
    "\n",
    "    :param file_path: Path to the JSON file.\n",
    "    :return: Parsed JSON content as a dictionary.\n",
    "    :raises: FileNotFoundError, json.JSONDecodeError\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Failed to decode JSON from file '{file_path}'.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResult:\n",
    "    def __init__(self, results_json: dict):\n",
    "        self.results_json = results_json\n",
    "    \n",
    "    @property\n",
    "    def args(self):\n",
    "        return self.results_json[\"args\"]\n",
    "    \n",
    "    @property\n",
    "    def model(self) -> dict:\n",
    "        return self.results_json[\"model\"]\n",
    "    \n",
    "    @property\n",
    "    def examples(self) -> dict:\n",
    "        return self.results_json[\"samples\"]\n",
    "    \n",
    "    @property\n",
    "    def explainer(self) -> str:\n",
    "        return self.results_json[\"explainer\"]\n",
    "    \n",
    "    @property\n",
    "    def tests(self) -> list[str]:\n",
    "        return self.results_json[\"tests\"]\n",
    "    \n",
    "    @property\n",
    "    def llo_threshold(self) -> float | None:\n",
    "        return self.results_json.get(\"sentence_similarity_threshold\")\n",
    "    \n",
    "    @property\n",
    "    def time_elapsed(self) -> str:\n",
    "        since_epoch = datetime.datetime.strptime(self.results_json[\"time_elapsed\"], \"%H:%M:%S.%f\")\n",
    "        time_elapsed = datetime.timedelta(\n",
    "            hours=since_epoch.hour,\n",
    "            minutes=since_epoch.minute,\n",
    "            seconds=since_epoch.second,\n",
    "            microseconds=since_epoch.microsecond\n",
    "        )\n",
    "        return time_elapsed\n",
    "    \n",
    "    def __repr__(self):\n",
    "        model = f\"Model: {self.model['full_model_name']} ({self.model['dtype']})\"\n",
    "        tests = f\"Tests: {self.tests}\"\n",
    "        explainer = f\"Explainer: {self.explainer})\"\n",
    "        examples = f\"Examples: {len(self.examples)}\"\n",
    "        args = f\"Args: {self.args}\"\n",
    "        time_elapsed = f\"Time elapsed: {self.time_elapsed}\"\n",
    "        llo_threshold = f\"LLO sim threshold: {self.llo_threshold}\"\n",
    "\n",
    "        return \"\\n\".join((model, tests, explainer, examples, args, time_elapsed, llo_threshold))\n",
    "\n",
    "    def examples_names(self) -> list[str]:\n",
    "        return list(self.examples.keys())\n",
    "\n",
    "    def get_example(self, example_name: str) -> dict:\n",
    "        return self.examples[example_name]\n",
    "    \n",
    "    def get_variable(self, variable):\n",
    "        cc_shap_cot_values = []\n",
    "        for example_name in self.examples_names():\n",
    "            cc_shap_score = self.get_example(example_name)[variable]\n",
    "            cc_shap_cot_values.append(float(cc_shap_score))\n",
    "\n",
    "        return np.array(cc_shap_cot_values)\n",
    "\n",
    "    def describe(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "\n",
    "        print(\"Mean: \", variable_values.mean())\n",
    "        print(\"Min: \", variable_values.min())\n",
    "        print(\"Max: \", variable_values.max())\n",
    "        print(\"Std dev: \", variable_values.std())\n",
    "    \n",
    "    def mean(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "        return variable_values.mean()\n",
    "\n",
    "    def boxplot(self, variable):\n",
    "        cc_shap_cot_values = self.get_variable(variable)\n",
    "\n",
    "        plt.boxplot(cc_shap_cot_values, orientation=\"horizontal\")\n",
    "        plt.xlim((-1.0, 1.0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResults:\n",
    "    def __init__(self, result_files: list[Path]):\n",
    "        self.result_files = result_files\n",
    "    \n",
    "    def load(self):\n",
    "        for file in self.result_files:\n",
    "            result_json = load_json_file(file)\n",
    "            yield ExperimentResult(result_json)\n",
    "    \n",
    "    def compare(self, variable, metric):\n",
    "        variable_values = []\n",
    "        for idx, result_file in enumerate(self.result_files):\n",
    "            result_json = load_json_file(result_file)\n",
    "            variable_value = ExperimentResult(result_json).get_variable(variable)\n",
    "            metric_value = metric(variable_value)\n",
    "            variable_values.append(metric_value)\n",
    "        return variable_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = Path(\"results_json\")\n",
    "\n",
    "COMVE = \"comve\"\n",
    "ESNLI = \"esnli\"\n",
    "DQA = \"disambiguation_qa\"\n",
    "\n",
    "LLAMA2 = \"llama2-7b-chat\"\n",
    "FALCON = \"falcon-7b-chat\"\n",
    "FALCON3 = \"falcon3-7B-chat\"\n",
    "\n",
    "EXPLAINER = \"partition\"\n",
    "\n",
    "comve_llama2 = result_dir / f\"{COMVE}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "esnli_llama2 = result_dir / f\"{ESNLI}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "dqa_llama2 = result_dir / f\"{DQA}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon = result_dir / f\"{COMVE}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "esnli_falcon = result_dir / f\"{ESNLI}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "dqa_falcon = result_dir / f\"{DQA}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon3 = result_dir / f\"{COMVE}_{FALCON3}_{100}_{EXPLAINER}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative: [ 1.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.\n",
      "  5.  5.  5.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  7.  8.  8.  9.  9.\n",
      "  9.  9. 10. 11. 11. 11. 11. 11. 12. 12. 12. 12. 13. 14. 14. 14. 14. 14.\n",
      " 14. 15. 15. 15. 15. 16. 16. 16. 16. 17. 17. 17. 18. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 20. 21. 21. 21. 21. 21. 21. 22. 22.\n",
      " 22. 22. 22. 22. 23. 23. 23. 23. 23. 23.] \n",
      "\n",
      "Differences: [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Transforms a cumulative array to a array of differences\n",
    "def cumsum_to_differences(cumsum_array):\n",
    "    return np.array([\n",
    "        cumsum_array[idx] - cumsum_array[idx - 1]\n",
    "        if idx != 0 else cumsum_array[idx]\n",
    "        for idx, _ in enumerate(cumsum_array)\n",
    "    ])\n",
    "\n",
    "in_expl_cumsum = ExperimentResult(\n",
    "    load_json_file(comve_llama2)\n",
    ").get_variable(\"atanasova_input_from_expl\")\n",
    "print(\"Cumulative:\", in_expl_cumsum, \"\\n\")\n",
    "print(\"Differences:\", cumsum_to_differences(in_expl_cumsum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: tiiuae/Falcon3-7B-Instruct (torch.float16)\n",
      "Tests: ['atanasova_counterfactual', 'atanasova_input_from_expl', 'cc_shap-posthoc', 'turpin', 'cc_shap-cot']\n",
      "Explainer: {'type': 'shap.explainers.Partition()', 'max_evaluations': 500})\n",
      "Examples: 100\n",
      "Args: Namespace(c_task='comve', model_name='falcon3-7B-chat', number_of_samples=100, explainer_type='partition', max_evaluations=500, classify_pred=False)\n",
      "Time elapsed: 4:59:40.848789\n",
      "LLO sim threshold: None\n"
     ]
    }
   ],
   "source": [
    "print(ExperimentResult(load_json_file(comve_falcon3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_arg(input_str, arg_name) -> str | None:\n",
    "    pattern = rf\"{arg_name}=(?:'([^']*)'|(\\d+))\"\n",
    "    match = re.search(pattern, input_str)\n",
    "    if match:\n",
    "        return match.group(1) or int(match.group(2))\n",
    "    return None\n",
    "\n",
    "experiments = [\n",
    "    comve_llama2,\n",
    "    esnli_llama2,\n",
    "    dqa_llama2,\n",
    "    comve_falcon,\n",
    "    esnli_falcon,\n",
    "    dqa_falcon,\n",
    "    comve_falcon3,\n",
    "]\n",
    "\n",
    "TEST_TO_VARIABLE_NAME = {\n",
    "    \"atanasova_counterfactual\": \"atanasova_counterfact\",\n",
    "    \"atanasova_input_from_expl\": \"atanasova_input_from_expl\",\n",
    "    \"cc_shap-posthoc\": \"cc_shap-posthoc\",\n",
    "    \"turpin\": \"turpin\",\n",
    "    \"cc_shap-cot\": \"cc_shap-cot\",\n",
    "    \"loo-posthoc\": \"loo_cosim_posthoc\",\n",
    "    \"loo-cot\": \"loo_cosim_cot\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for experiment in experiments:\n",
    "    experiment = ExperimentResult(load_json_file(experiment))\n",
    "    args = experiment.args\n",
    "    short_model_name = find_arg(args, \"model_name\")\n",
    "    dataset = find_arg(args, \"c_task\")\n",
    "    n_samples = find_arg(args, \"number_of_samples\")\n",
    "\n",
    "    assert n_samples == len(experiment.examples_names()), \"Number of samples from args is different than actual number of samples\"\n",
    "\n",
    "    for test in experiment.tests:\n",
    "        variable_name = TEST_TO_VARIABLE_NAME[test]\n",
    "        test_results = experiment.get_variable(variable_name)\n",
    "\n",
    "        # The \"atanasova_input_from_expl\" keeps a counter and not 0 or 1\n",
    "        # per sample\n",
    "        if test == \"atanasova_input_from_expl\":\n",
    "            test_results = cumsum_to_differences(test_results)\n",
    "\n",
    "        mean = np.mean(test_results)\n",
    "        std = np.std(test_results)\n",
    "        min_val = np.min(test_results)\n",
    "        max_val = np.max(test_results)\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": short_model_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_samples\": n_samples,\n",
    "            \"test\": test,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "\n",
    "experimentsresults_dataframe = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>test</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>-0.0243</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.126175</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.121106</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.200265</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.191141</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.113236</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.493559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1663</td>\n",
       "      <td>0.192331</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.089853</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.088299</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model            dataset  n_samples                       test  \\\n",
       "0    llama2-7b-chat              comve        100   atanasova_counterfactual   \n",
       "1    llama2-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "2    llama2-7b-chat              comve        100            cc_shap-posthoc   \n",
       "3    llama2-7b-chat              comve        100                     turpin   \n",
       "4    llama2-7b-chat              comve        100                cc_shap-cot   \n",
       "5    llama2-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "6    llama2-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "7    llama2-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "8    llama2-7b-chat              esnli        100                     turpin   \n",
       "9    llama2-7b-chat              esnli        100                cc_shap-cot   \n",
       "10   llama2-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "11   llama2-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "12   llama2-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "13   llama2-7b-chat  disambiguation_qa        100                     turpin   \n",
       "14   llama2-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "15   falcon-7b-chat              comve        100   atanasova_counterfactual   \n",
       "16   falcon-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "17   falcon-7b-chat              comve        100            cc_shap-posthoc   \n",
       "18   falcon-7b-chat              comve        100                     turpin   \n",
       "19   falcon-7b-chat              comve        100                cc_shap-cot   \n",
       "20   falcon-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "21   falcon-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "22   falcon-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "23   falcon-7b-chat              esnli        100                     turpin   \n",
       "24   falcon-7b-chat              esnli        100                cc_shap-cot   \n",
       "25   falcon-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "26   falcon-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "27   falcon-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "28   falcon-7b-chat  disambiguation_qa        100                     turpin   \n",
       "29   falcon-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "30  falcon3-7B-chat              comve        100   atanasova_counterfactual   \n",
       "31  falcon3-7B-chat              comve        100  atanasova_input_from_expl   \n",
       "32  falcon3-7B-chat              comve        100            cc_shap-posthoc   \n",
       "33  falcon3-7B-chat              comve        100                     turpin   \n",
       "34  falcon3-7B-chat              comve        100                cc_shap-cot   \n",
       "\n",
       "      mean       std   min   max  \n",
       "0   0.8600  0.346987  0.00  1.00  \n",
       "1   0.2300  0.420833  0.00  1.00  \n",
       "2  -0.0243  0.105245 -0.24  0.37  \n",
       "3   0.6000  0.489898  0.00  1.00  \n",
       "4  -0.1027  0.106910 -0.35  0.33  \n",
       "5   0.5200  0.499600  0.00  1.00  \n",
       "6   0.0000  0.000000  0.00  0.00  \n",
       "7   0.1241  0.126175 -0.17  0.39  \n",
       "8   0.3100  0.462493  0.00  1.00  \n",
       "9   0.0812  0.121106 -0.24  0.34  \n",
       "10  0.7600  0.427083  0.00  1.00  \n",
       "11  0.0000  0.000000  0.00  0.00  \n",
       "12  0.0800  0.200265 -0.32  0.52  \n",
       "13  0.3800  0.485386  0.00  1.00  \n",
       "14  0.0605  0.191141 -0.43  0.62  \n",
       "15  0.2300  0.420833  0.00  1.00  \n",
       "16  0.0000  0.000000  0.00  0.00  \n",
       "17  0.1232  0.082667 -0.06  0.33  \n",
       "18  0.5700  0.495076  0.00  1.00  \n",
       "19  0.0436  0.102747 -0.33  0.53  \n",
       "20  0.3100  0.462493  0.00  1.00  \n",
       "21  0.0000  0.000000  0.00  0.00  \n",
       "22  0.1642  0.079501 -0.02  0.43  \n",
       "23  0.0800  0.271293  0.00  1.00  \n",
       "24  0.0658  0.113236 -0.27  0.28  \n",
       "25  0.4200  0.493559  0.00  1.00  \n",
       "26  0.0000  0.000000  0.00  0.00  \n",
       "27  0.0821  0.094491 -0.16  0.36  \n",
       "28  0.4000  0.489898  0.00  1.00  \n",
       "29 -0.1663  0.192331 -0.47  0.51  \n",
       "30  0.8500  0.357071  0.00  1.00  \n",
       "31  0.4900  0.499900  0.00  1.00  \n",
       "32  0.3462  0.089853  0.15  0.62  \n",
       "33  0.9100  0.286182  0.00  1.00  \n",
       "34  0.5085  0.088299  0.29  0.77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experimentsresults_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLO Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/rick/.cache/huggingface/datasets/sentence-transformers___parquet/sentence-transformers--stsb-3f9e65f9f13e8bdf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc93c0d8ca46aa90df3a256eb2e8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STS dataset from huggingface\n",
    "# https://huggingface.co/datasets/sentence-transformers/stsb \n",
    "sts_dataset = load_dataset(\"sentence-transformers/stsb\")\n",
    "test_sts_dataset = sts_dataset.get(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "random_idx = rng.integers(\n",
    "    0,\n",
    "    len(test_sts_dataset),\n",
    "    size=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meat is being put into a skillet.\n",
      "A woman is putting a baby into a trash can.\n",
      "Score: 0.08, Predicted similarity: 0.06008784472942352 \n",
      "\n",
      "I think we made the right case and did the right thing.\"\n",
      "Mr Blair went on: \"I think we did the right thing in relation to Iraq.\n",
      "Score: 0.55, Predicted similarity: 0.5586273670196533 \n",
      "\n",
      "The consensus among Wall Street analysts was for a loss of 28 cents a share.\n",
      "Analysts surveyed by First Call were expecting sales of $723 million and a loss of 28 cents a share.\n",
      "Score: 0.6, Predicted similarity: 0.645268440246582 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence_idx in enumerate(random_idx):\n",
    "    sentence_pair_similarity = test_sts_dataset[int(sentence_idx)]\n",
    "    sentence_1 = sentence_pair_similarity[\"sentence1\"]\n",
    "    sentence_2 = sentence_pair_similarity[\"sentence2\"]\n",
    "    pair = [sentence_1, sentence_2]\n",
    "    encoded_sentences = encoder.encode(pair)\n",
    "    similarity = cosine_similarity(encoded_sentences[0:1], encoded_sentences[1:2])[0][0]\n",
    "\n",
    "    print(\"\\n\".join((\n",
    "        sentence_1,\n",
    "        sentence_2,\n",
    "        f\"Score: {sentence_pair_similarity['score']}, Predicted similarity: {similarity}\"\n",
    "    )), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f566747f2b2a44058a5309fa3c87f470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity_diff = []\n",
    "\n",
    "for idx, sentence_pair_similarity in tqdm(enumerate(test_sts_dataset), total=len(test_sts_dataset)):\n",
    "    sentence_1 = sentence_pair_similarity[\"sentence1\"]\n",
    "    sentence_2 = sentence_pair_similarity[\"sentence2\"]\n",
    "    pair = [sentence_1, sentence_2]\n",
    "    encoded_sentences = encoder.encode(pair)\n",
    "    similarity = cosine_similarity(encoded_sentences[0:1], encoded_sentences[1:2])[0][0]\n",
    "\n",
    "    diff = np.abs(sentence_pair_similarity['score'] - similarity)\n",
    "    similarity_diff.append(diff)\n",
    "similarity_diff = np.array(similarity_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity diff: 0.14835433425672184\n",
      "Similarity diff: 0.05377726495265958\n",
      "Similarity std: 0.12167999185250436\n",
      "Similarity min: 6.411552429197442e-05\n",
      "Similarity max: 0.7355060532689095\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity diff:\", np.mean(similarity_diff))\n",
    "print(\"Similarity diff:\", np.quantile(similarity_diff, 0.25))\n",
    "print(\"Similarity std:\", np.std(similarity_diff))\n",
    "print(\"Similarity min:\", np.min(similarity_diff))\n",
    "print(\"Similarity max:\", np.max(similarity_diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfaUlEQVR4nO3dfXzO9f////sx247NbMPOGHOS81BEKcnZEJKSfuktpdK7EyWnedPJ2+otC5Heik7eQmlUbyfvohMUcpKcpSjnzUy2piVzMjt9/v7w3fFx2IbtdRx2HHa7Xi7HJcfz9Xw9X4/Xc0dz3L3ObMYYIwAAAACwwKesCwAAAADg/QgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgA83pw5c2Sz2bRly5Yil/fq1Ut16tRxaqtTp44efPDBEm1nw4YNiouL019//VW6Qsu58+f8yJEjiouL0/bt2wv1ffDBB1WpUqVSb6tjx46y2WyOl5+fn+rUqaNBgwYpKSmp1OO60urVq2Wz2bR69eoSr1vSz2JcXJzTfPj4+Kh69erq2bOn1q9fX+LtFyjN/0cAyi/fsi4AANxh8eLFCgkJKdE6GzZs0IsvvqgHH3xQlStXdk9hV7Dz5/zIkSN68cUXVadOHbVo0cLl27vqqqv04YcfSpKys7O1c+dOvfjii1qxYoV2796tihUrunybl0tpP4tffvmlQkNDlZ+fr0OHDmnSpEnq2LGjvv/+e1133XXuKxgARLAAcIVq2bJlWZdQYjk5ObLZbPL19c5fzZd7zgMDA3XjjTc63rdv314BAQEaNGiQ1q1bp27dul3WejxBq1atFB4eLklq27atbrjhBtWrV0///e9/CRYA3I5ToQBckc4/hSM/P1/jx49Xo0aNFBgYqMqVK+uaa67R66+/LunsqSTPPPOMJKlu3bqOU0oKTmPJz8/XpEmT1LhxY9ntdkVGRuqBBx7Q4cOHnbZrjNGECRNUu3ZtBQQEqHXr1lqxYoU6duyojh07OvoVnCbzwQcfaOTIkapRo4bsdrv279+vo0ePavDgwbr66qtVqVIlRUZGqnPnzlq7dq3Ttg4ePCibzabJkydr4sSJqlOnjgIDA9WxY0ft3btXOTk5GjNmjKKjoxUaGqo+ffooLS3tgvO2bNky2Ww2bd682dG2cOFC2Ww23XbbbU59r7nmGvXt27fIOV+9erWuv/56SdJDDz3kmM+4uDinMfbv36+ePXuqUqVKiomJ0ciRI5WVlXXBGi8kNDRUkuTn5+fUvm7dOsXGxio4OFgVK1ZU27ZttWzZMqflfn5+GjVqlNN6BafhzZo1y9Fms9n01FNP6e2331bDhg1lt9t19dVXa8GCBZdU46effqqbbrpJFStWVHBwsLp27arvvvvOsfxin8WSKG4+MjIyNGrUKNWtW1f+/v6qUaOGhg0bplOnTl10zEOHDmnAgAGKjIyU3W5XkyZNNGXKFOXn5zv6XH/99YU+L82bNy/02Vq0aJFsNpt27NhR4n0D4IEMAHi42bNnG0lm48aNJicnp9CrZ8+epnbt2k7r1K5d2wwcONDxPj4+3lSoUMGMGzfOfP311+bLL78006ZNM3FxccYYY5KTk82QIUOMJLNo0SLz3Xffme+++84cP37cGGPMo48+aiSZp556ynz55ZfmrbfeMhERESYmJsYcPXrUsZ2xY8caSebRRx81X375pXn33XdNrVq1TPXq1U2HDh0c/VatWmUkmRo1api7777bfPrpp2bp0qUmPT3d7N692zzxxBNmwYIFZvXq1Wbp0qVm0KBBxsfHx6xatcoxRmJiopFkateubW6//XazdOlSM2/ePBMVFWUaNmxo7r//fvPwww+bL774wrz11lumUqVK5vbbb7/gXJ84ccL4+fmZCRMmONoef/xxExgYaIKCgkx2drYxxpjff//d2Gw2M2PGjCLn/Pjx446f2/PPP++Yz+TkZGOMMQMHDjT+/v6mSZMm5tVXXzUrV640//znP43NZjMvvvjihT8QxpgOHTqYpk2bOj4Dp06dMt9//7255pprzFVXXWXOnDnj6Lt69Wrj5+dnWrVqZT766COzZMkS061bN2Oz2cyCBQsc/V555RUjyfzvf/8zxhizc+dOU7FiRTNgwACnbUsyMTEx5uqrrzbz5883n376qenevbuRZD755JNCP+Nzf2YffvihkWS6detmlixZYj766CPTqlUr4+/vb9auXWuMufhnsSjjxo0zkkxqaqrJyckxWVlZZt++faZfv37Gbrebn376ydH31KlTpkWLFiY8PNxMnTrVrFy50rz++usmNDTUdO7c2eTn5xf5MzXGmLS0NFOjRg0TERFh3nrrLfPll1+ap556ykgyTzzxhKPfmDFjTKVKlRyfl9TUVCPJBAYGmpdfftnR74knnjBRUVHF7hcA70KwAODxCr6gXuh1sWDRq1cv06JFiwtuZ/LkyUaSSUxMdGrftWuXkWQGDx7s1P79998bSebZZ581xhjz559/Grvdbvr16+fU77vvvjOSigwW7du3v+j+5+bmmpycHBMbG2v69OnjaC8IFtdee63Jy8tztE+bNs1IMr1793YaZ9iwYUbSBb+gGmNMu3btTOfOnR3v69evb5555hnj4+Nj1qxZY4z5vy/Ie/fudfQ7f843b95sJJnZs2cX2sbAgQONJPPxxx87tffs2dM0atTogvUZczZYFPU5aNiwodm1a5dT3xtvvNFERkaaEydOONpyc3NNs2bNTM2aNR1fpPPz803Pnj1N5cqVzc6dO83VV19tGjdubE6ePOk0XsEX5NTUVKfxGjdubOrXr+9oOz9Y5OXlmejoaNO8eXOnn9eJEydMZGSkadu2raOtuM9icQqCxfmvkJAQs2jRIqe+8fHxxsfHx2zevNmp/b///a+RZD7//HNH2/k/0zFjxhhJ5vvvv3da94knnjA2m83s2bPHGGPMypUrjSTz7bffGmOMmTdvngkODjaDBw82nTp1cqzXoEED079//0vaRwCej1OhAHiN999/X5s3by70ateu3UXXveGGG/Tjjz9q8ODB+uqrr5SRkXHJ2121apUkFbo7zg033KAmTZro66+/liRt3LhRWVlZuueee5z63XjjjYXuWlXg3FOJzvXWW2/puuuuU0BAgHx9feXn56evv/5au3btKtS3Z8+e8vH5v1/nTZo0kaRCp6IUtB86dKiYPT0rNjZW69evV2ZmppKSkrR//37de++9atGihVasWCFJWrlypWrVqqUGDRpccKwLsdlsuv32253arrnmmku+q1O9evUcn4HvvvtOCQkJCgwMVGxsrPbt2ydJOnXqlL7//nvdfffdTnehqlChgu6//34dPnxYe/bscdTz/vvvKzg4WK1bt1ZiYqI+/vhjBQUFFdp2bGysoqKinMbr16+f9u/fX+j0uAJ79uzRkSNHdP/99zv9vCpVqqS+fftq48aNOn369CXte3FWrlypzZs3a9OmTVq6dKm6dOmie++9V4sXL3b0Wbp0qZo1a6YWLVooNzfX8br11lsvesrVN998o6uvvlo33HCDU/uDDz4oY4y++eYbSdLNN9+sgIAArVy5UpIcpwN2795dGzZs0OnTp5WcnKx9+/apS5culvYZgOcgWADwGk2aNFHr1q0LvQrOI7+QsWPH6tVXX9XGjRvVo0cPhYWFKTY2tthb2J4rPT1dklS9evVCy6Kjox3LC/577hfOAkW1FTfm1KlT9cQTT6hNmzZauHChNm7cqM2bN6t79+7KzMws1L9q1apO7/39/S/YfubMmSJrKdClSxdlZWVp3bp1WrFihcLDw9WyZUt16dLF8UXx66+/tvyFsGLFigoICHBqs9vtF62vQME1LK1bt9aNN96ov/3tb/riiy+UkpKif/7zn5KkY8eOyRhT7M9O+r+fmySFhYWpd+/eOnPmjLp3767mzZsXue1q1aoV23bueOe62OcoPz9fx44du9AuX9S1116r1q1bO65x+OSTT1S/fn09+eSTjj6///67fvrpJ/n5+Tm9goODZYzRH3/8Uez46enplzSXAQEBuvnmm50+L127dlXHjh2Vl5entWvXOkIqwQK4cnjnrUcAoIR8fX01YsQIjRgxQn/99ZdWrlypZ599VrfeequSk5MveGvSsLAwSVJKSopq1qzptOzIkSOOu/AU9Pv9998LjZGamlrkUQubzVaobd68eerYsaNmzpzp1H7ixIkL76SLtGnTRpUqVdLKlSt18OBBxcbGymazKTY2VlOmTNHmzZt16NAhj/xCWL16dYWHh+vHH3+UJFWpUkU+Pj5KSUkp1PfIkSOS5Pj5SWf/ZX3mzJm64YYbtHjxYi1cuLDIo0qpqanFthV8Ds537ueoqFp8fHxUpUqVi+1iifj4+Khp06b65JNPlJaWpsjISIWHhyswMFDvvfdekeucOx/nCwsLu+S5jI2N1T//+U9t2rRJhw8fVteuXRUcHKzrr79eK1as0JEjR9SwYUPFxMRY3EsAnoIjFgDKncqVK+vuu+/Wk08+qT///FMHDx6UdPZfyyUVOirQuXNnSWe/8J9r8+bN2rVrl2JjYyWd/UJut9v10UcfOfXbuHFjiR7aZrPZHLUU+Omnn5zuHOROfn5+at++vVasWKFvvvlGXbt2lSTdcsst8vX11fPPP+8IGhdS3Hy60+HDh/XHH38oMjJSkhQUFKQ2bdpo0aJFTnXk5+dr3rx5qlmzpho2bCjp7Bf+AQMGqEOHDtqwYYN69+6tQYMGKTExsdB2vv76a6cAmZeXp48++kj16tUrFD4LNGrUSDVq1FBCQoKMMY72U6dOaeHChY47RUmum7u8vDzt2LFDdrvd8YyRXr166cCBAwoLCyvyCGBxp+1JZ8PCL7/8om3btjm1v//++7LZbOrUqZOjrUuXLsrNzdULL7ygmjVrqnHjxo72lStX6ptvvvHIcAqg9DhiAaBcuP3229WsWTO1bt1aERERSkpK0rRp01S7dm3HdQIFp728/vrrGjhwoPz8/NSoUSM1atRIjz76qKZPny4fHx/16NFDBw8e1AsvvKCYmBgNHz5c0tlTj0aMGKH4+HhVqVJFffr00eHDh/Xiiy+qevXqTufVX0ivXr30r3/9S+PGjVOHDh20Z88evfTSS6pbt65yc3PdM0HniY2N1ciRIyX936kqgYGBatu2rZYvX65rrrnG8eW9OPXq1VNgYKA+/PBDNWnSRJUqVVJ0dLTjtBmrMjMztXHjRklnv0AnJiZq0qRJkqRhw4Y5+sXHx6tr167q1KmTRo0aJX9/f82YMUM7d+7U/PnzZbPZlJeXp7/97W+y2WxKSEhQhQoVNGfOHLVo0UL9+vXTunXrHKeSSWf/Zb5z58564YUXFBQUpBkzZmj37t0XvOWsj4+PJk2apPvuu0+9evXSY489pqysLE2ePFl//fWXXnnlFUff4j6LwcHBF5yTrVu3Ok4N/P333/Xee+9p9+7dGj58uOO0s2HDhmnhwoVq3769hg8frmuuucbxQL3ly5dr5MiRatOmTZHjDx8+XO+//75uu+02vfTSS6pdu7aWLVumGTNm6IknnnCENOnsMzWqVKmi5cuX66GHHnK0d+nSRf/6178cfwZwBSnba8cB4OIK7gp1/l1sCtx2220XvSvUlClTTNu2bU14eLjx9/c3tWrVMoMGDTIHDx50Wm/s2LEmOjra+Pj4FLqjz8SJE03Dhg2Nn5+fCQ8PNwMGDHDcPrVAfn6+GT9+vKlZs6bx9/c311xzjVm6dKm59tprne7oVHDHoHNvT1ogKyvLjBo1ytSoUcMEBASY6667zixZssQMHDjQaT8L7go1efJkp/WLG/ti83iuH3/80UgyDRo0cGp/+eWXjSQzYsSIQuucP+fGGDN//nzTuHFj4+fnZySZcePGGWPO3hUqKCio0BgFdze6mPPvCuXj42Oio6NNjx49zOrVqwv1X7t2rencubMJCgoygYGB5sYbbzSfffaZY/lzzz1nfHx8zNdff+203oYNG4yvr68ZOnSoo02SefLJJ82MGTNMvXr1jJ+fn2ncuLH58MMPndYt6nazxhizZMkS06ZNGxMQEGCCgoJMbGysWb9+faGai/ssFqWou0JVrVrVtGnTxrz33ntOd6EyxpiTJ0+a559/3jRq1Mj4+/ub0NBQ07x5czN8+HCnu10V9TNNSkoy/fv3N2FhYcbPz880atTITJ48udA2jDGmT58+RpLT3GRnZ5ugoCDj4+Njjh07Vuw+AfA+NmPOOR4LAHC5xMRENW7cWOPGjdOzzz5b1uXAIpvNpieffFJvvPFGWZcCAB6FU6EAwIV+/PFHzZ8/X23btlVISIj27NmjSZMmKSQkRIMGDSrr8gAAcBuCBQC4UFBQkLZs2aJZs2bpr7/+UmhoqDp27KiXX3652FvOAgBwJeBUKAAAAACWcbtZAAAAAJYRLAAAAABYRrAAAAAAYBkXb+vsE1iPHDmi4OBg2Wy2si4HAAAA8AjGGJ04cULR0dEXfdArwULSkSNHFBMTU9ZlAAAAAB4pOTlZNWvWvGAfgoWk4OBgSWcnLCQkpIyrAQAAADxDRkaGYmJiHN+XL4RgITlOfwoJCSFYAAAAAOe5lMsFuHgbAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACW+ZZ1ATjr6NGjysjIcPm4ISEhioiIcPm4AAAAwLkIFh7g6NGj6t//CaWnZ7l87LAwuxISZhIuAAAA4FYECw+QkZGh9PQs2e0jFRgY47JxMzOTlZ4+RRkZGQQLAAAAuBXBwoMEBsYoKKieS8fMcv1BEAAAAKAQLt4GAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlZRosvv32W91+++2Kjo6WzWbTkiVLCvXZtWuXevfurdDQUAUHB+vGG2/UoUOHHMuzsrI0ZMgQhYeHKygoSL1799bhw4cv414AAAAAKNNgcerUKV177bV64403ilx+4MABtWvXTo0bN9bq1av1448/6oUXXlBAQICjz7Bhw7R48WItWLBA69at08mTJ9WrVy/l5eVdrt0AAAAAyj3fstx4jx491KNHj2KXP/fcc+rZs6cmTZrkaLvqqqscfz5+/LhmzZqlDz74QF26dJEkzZs3TzExMVq5cqVuvfVW9xUPAAAAwMFjr7HIz8/XsmXL1LBhQ916662KjIxUmzZtnE6X2rp1q3JyctStWzdHW3R0tJo1a6YNGzaUQdUAAABA+eSxwSItLU0nT57UK6+8ou7du2v58uXq06eP7rrrLq1Zs0aSlJqaKn9/f1WpUsVp3aioKKWmphY7dlZWljIyMpxeAAAAAEqvTE+FupD8/HxJ0h133KHhw4dLklq0aKENGzborbfeUocOHYpd1xgjm81W7PL4+Hi9+OKLri0YAAAAKMc89ohFeHi4fH19dfXVVzu1N2nSxHFXqGrVqik7O1vHjh1z6pOWlqaoqKhixx47dqyOHz/ueCUnJ7t+BwAAAIByxGODhb+/v66//nrt2bPHqX3v3r2qXbu2JKlVq1by8/PTihUrHMtTUlK0c+dOtW3bttix7Xa7QkJCnF4AAAAASq9MT4U6efKk9u/f73ifmJio7du3q2rVqqpVq5aeeeYZ9evXT+3bt1enTp305Zdf6rPPPtPq1aslSaGhoRo0aJBGjhypsLAwVa1aVaNGjVLz5s0dd4kCAAAA4H5lGiy2bNmiTp06Od6PGDFCkjRw4EDNmTNHffr00VtvvaX4+Hg9/fTTatSokRYuXKh27do51nnttdfk6+ure+65R5mZmYqNjdWcOXNUoUKFy74/AAAAQHlVpsGiY8eOMsZcsM/DDz+shx9+uNjlAQEBmj59uqZPn+7q8gAAAABcIo+9xgIAAACA9yBYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAs8y3rAuBeOTlZSkpKcvm4ISEhioiIcPm4AAAA8E4EiytYdna6kpJ+1ZAhr8hut7t07LAwuxISZhIuAAAAIIlgcUXLyzup3Fx/+fsPV+XKDV02bmZmstLTpygjI4NgAQAAAEkEi3IhIKCmgoLquXTMrCyXDgcAAAAvx8XbAAAAACwjWAAAAACwjFOhUCruuNsUd5oCAADwXgQLlJi77jbFnaYAAAC8F8ECJeaOu01xpykAAADvRrBAqbn6blPcaQoAAMB7cfE2AAAAAMsIFgAAAAAsI1gAAAAAsKxMg8W3336r22+/XdHR0bLZbFqyZEmxfR977DHZbDZNmzbNqT0rK0tDhgxReHi4goKC1Lt3bx0+fNi9hQMAAABwUqbB4tSpU7r22mv1xhtvXLDfkiVL9P333ys6OrrQsmHDhmnx4sVasGCB1q1bp5MnT6pXr17Ky8tzV9kAAAAAzlOmd4Xq0aOHevToccE+v/32m5566il99dVXuu2225yWHT9+XLNmzdIHH3ygLl26SJLmzZunmJgYrVy5UrfeeqvbagcAAADwfzz6Gov8/Hzdf//9euaZZ9S0adNCy7du3aqcnBx169bN0RYdHa1mzZppw4YNxY6blZWljIwMpxcAAACA0vPoYDFx4kT5+vrq6aefLnJ5amqq/P39VaVKFaf2qKgopaamFjtufHy8QkNDHa+YmBiX1g0AAACUNx4bLLZu3arXX39dc+bMkc1mK9G6xpgLrjN27FgdP37c8UpOTrZaLgAAAFCueWywWLt2rdLS0lSrVi35+vrK19dXSUlJGjlypOrUqSNJqlatmrKzs3Xs2DGnddPS0hQVFVXs2Ha7XSEhIU4vAAAAAKXnscHi/vvv108//aTt27c7XtHR0XrmmWf01VdfSZJatWolPz8/rVixwrFeSkqKdu7cqbZt25ZV6QAAAEC5U6Z3hTp58qT279/veJ+YmKjt27eratWqqlWrlsLCwpz6+/n5qVq1amrUqJEkKTQ0VIMGDdLIkSMVFhamqlWratSoUWrevLnjLlEAAAAA3K9Mg8WWLVvUqVMnx/sRI0ZIkgYOHKg5c+Zc0hivvfaafH19dc899ygzM1OxsbGaM2eOKlSo4I6SAQAAABShTINFx44dZYy55P4HDx4s1BYQEKDp06dr+vTpLqwMAAAAQEl47DUWAAAAALwHwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhWpg/IA86Vk5OlpKQkl48bEhKiiIgIl48LAACA/0OwgEfIzk5XUtKvGjLkFdntdpeOHRZmV0LCTMIFAACAGxEs4BHy8k4qN9df/v7DVblyQ5eNm5mZrPT0KcrIyCBYAAAAuBHBAh4lIKCmgoLquXTMrCyXDgcAAIAicPE2AAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAy8o0WHz77be6/fbbFR0dLZvNpiVLljiW5eTk6B//+IeaN2+uoKAgRUdH64EHHtCRI0ecxsjKytKQIUMUHh6uoKAg9e7dW4cPH77MewIAAACUb2UaLE6dOqVrr71Wb7zxRqFlp0+f1rZt2/TCCy9o27ZtWrRokfbu3avevXs79Rs2bJgWL16sBQsWaN26dTp58qR69eqlvLy8y7UbAAAAQLnnW5Yb79Gjh3r06FHkstDQUK1YscKpbfr06brhhht06NAh1apVS8ePH9esWbP0wQcfqEuXLpKkefPmKSYmRitXrtStt97q9n0AAAAA4GXXWBw/flw2m02VK1eWJG3dulU5OTnq1q2bo090dLSaNWumDRs2FDtOVlaWMjIynF4AAAAASs9rgsWZM2c0ZswY9e/fXyEhIZKk1NRU+fv7q0qVKk59o6KilJqaWuxY8fHxCg0NdbxiYmLcWjsAAABwpfOKYJGTk6N7771X+fn5mjFjxkX7G2Nks9mKXT527FgdP37c8UpOTnZluQAAAEC54/HBIicnR/fcc48SExO1YsUKx9EKSapWrZqys7N17Ngxp3XS0tIUFRVV7Jh2u10hISFOLwAAAACl59HBoiBU7Nu3TytXrlRYWJjT8latWsnPz8/pIu+UlBTt3LlTbdu2vdzlAgAAAOVWmd4V6uTJk9q/f7/jfWJiorZv366qVasqOjpad999t7Zt26alS5cqLy/Pcd1E1apV5e/vr9DQUA0aNEgjR45UWFiYqlatqlGjRql58+aOu0QBAAAAcL8yDRZbtmxRp06dHO9HjBghSRo4cKDi4uL06aefSpJatGjhtN6qVavUsWNHSdJrr70mX19f3XPPPcrMzFRsbKzmzJmjChUqXJZ9AAAAAFDGwaJjx44yxhS7/ELLCgQEBGj69OmaPn26K0sDAAAAUAIefY0FAAAAAO9AsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYVqZP3gYuh5ycLCUlJbl83JCQEEVERLh8XAAAAG9EsMAVLTs7XUlJv2rIkFdkt9tdOnZYmF0JCTMJFwAAACJY4AqXl3dSubn+8vcfrsqVG7ps3MzMZKWnT1FGRgbBAgAAQAQLlBMBATUVFFTPpWNmZbl0OAAAAK/GxdsAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIzbzQKl5I4nevM0bwAA4K0IFkApuOuJ3jzNGwAAeKtSBYvExETVrVvX1bUAXsMdT/Tmad4AAMCblSpY1K9fX+3bt9egQYN09913KyAgwNV1AV7B1U/05mneAADAW5Xq4u0ff/xRLVu21MiRI1WtWjU99thj2rRpk6trAwAAAOAlShUsmjVrpqlTp+q3337T7NmzlZqaqnbt2qlp06aaOnWqjh496uo6AQAAAHgwS7eb9fX1VZ8+ffTxxx9r4sSJOnDggEaNGqWaNWvqgQceUEpKiqvqBAAAAODBLAWLLVu2aPDgwapevbqmTp2qUaNG6cCBA/rmm2/022+/6Y477nBVnQAAAAA8WKku3p46dapmz56tPXv2qGfPnnr//ffVs2dP+ficzSl169bV22+/rcaNG7u0WAAAAACeqVTBYubMmXr44Yf10EMPqVq1akX2qVWrlmbNmmWpOAAAAADeoVSnQu3bt09jx44tNlRIkr+/vwYOHHjBcb799lvdfvvtio6Ols1m05IlS5yWG2MUFxen6OhoBQYGqmPHjvr555+d+mRlZWnIkCEKDw9XUFCQevfurcOHD5dmtwAAAACUUqmCxezZs/XJJ58Uav/kk080d+7cSx7n1KlTuvbaa/XGG28UuXzSpEmaOnWq3njjDW3evFnVqlVT165ddeLECUefYcOGafHixVqwYIHWrVunkydPqlevXsrLyyv5jgEAAAAolVIFi1deeUXh4eGF2iMjIzVhwoRLHqdHjx4aP3687rrrrkLLjDGaNm2annvuOd11111q1qyZ5s6dq9OnTyshIUGSdPz4cc2aNUtTpkxRly5d1LJlS82bN087duzQypUrS7NrAAAAAEqhVMEiKSlJdevWLdReu3ZtHTp0yHJRkpSYmKjU1FR169bN0Wa329WhQwdt2LBBkrR161bl5OQ49YmOjlazZs0cfQAAAAC4X6mCRWRkpH766adC7T/++KPCwsIsFyVJqampkqSoqCin9qioKMey1NRU+fv7q0qVKsX2KUpWVpYyMjKcXgAAAABKr1TB4t5779XTTz+tVatWKS8vT3l5efrmm280dOhQ3XvvvS4t0GazOb03xhRqO9/F+sTHxys0NNTxiomJcUmtAAAAQHlVqmAxfvx4tWnTRrGxsQoMDFRgYKC6deumzp07l+gaiwspuOPU+Uce0tLSHEcxqlWrpuzsbB07dqzYPkUZO3asjh8/7nglJye7pGYAAACgvCpVsPD399dHH32k3bt368MPP9SiRYt04MABvffee/L393dJYXXr1lW1atW0YsUKR1t2drbWrFmjtm3bSpJatWolPz8/pz4pKSnauXOno09R7Ha7QkJCnF4AAAAASq9UD8gr0LBhQzVs2LDU6588eVL79+93vE9MTNT27dtVtWpV1apVS8OGDdOECRPUoEEDNWjQQBMmTFDFihXVv39/SVJoaKgGDRqkkSNHKiwsTFWrVtWoUaPUvHlzdenSxcquAQAAACiBUgWLvLw8zZkzR19//bXS0tKUn5/vtPybb765pHG2bNmiTp06Od6PGDFCkjRw4EDNmTNHo0ePVmZmpgYPHqxjx46pTZs2Wr58uYKDgx3rvPbaa/L19dU999yjzMxMxcbGas6cOapQoUJpdg0AAABAKZQqWAwdOlRz5szRbbfdpmbNml30YuridOzYUcaYYpfbbDbFxcUpLi6u2D4BAQGaPn26pk+fXqoaAAAAAFhXqmCxYMECffzxx+rZs6er6wEAAADghUp98Xb9+vVdXQsAAAAAL1WqYDFy5Ei9/vrrFzyNCQAAAED5UapTodatW6dVq1bpiy++UNOmTeXn5+e0fNGiRS4pDgAAAIB3KFWwqFy5svr06ePqWgAAAAB4qVIFi9mzZ7u6DgAAAABerFTXWEhSbm6uVq5cqbffflsnTpyQJB05ckQnT550WXEAAAAAvEOpjlgkJSWpe/fuOnTokLKystS1a1cFBwdr0qRJOnPmjN566y1X1wkAAADAg5XqiMXQoUPVunVrHTt2TIGBgY72Pn366Ouvv3ZZcQAAAAC8Q6nvCrV+/Xr5+/s7tdeuXVu//fabSwoDyqOcnCwlJSW5fNyQkBBFRES4fFwAAIACpQoW+fn5ysvLK9R++PBhBQcHWy4KKI+ys9OVlPSrhgx5RXa73aVjh4XZlZAwk3ABAADcplTBomvXrpo2bZreeecdSZLNZtPJkyc1btw49ezZ06UFAuVFXt5J5eb6y99/uCpXbuiycTMzk5WePkUZGRkECwAA4DalChavvfaaOnXqpKuvvlpnzpxR//79tW/fPoWHh2v+/PmurhEoVwICaiooqJ5Lx8zKculwAAAAhZQqWERHR2v79u2aP3++tm3bpvz8fA0aNEj33Xef08XcAAAAAMqHUgULSQoMDNTDDz+shx9+2JX1AAAAAPBCpQoW77///gWXP/DAA6UqBgAAAIB3KlWwGDp0qNP7nJwcnT59Wv7+/qpYsSLBAgAAAChnSvWAvGPHjjm9Tp48qT179qhdu3ZcvA0AAACUQ6UKFkVp0KCBXnnllUJHMwAAAABc+VwWLCSpQoUKOnLkiCuHBAAAAOAFSnWNxaeffur03hijlJQUvfHGG7r55ptdUhgAAAAA71GqYHHnnXc6vbfZbIqIiFDnzp01ZcoUV9QFAAAAwIuUKljk5+e7ug4AAAAAXsyl11gAAAAAKJ9KdcRixIgRl9x36tSppdkEAAAAAC9SqmDxww8/aNu2bcrNzVWjRo0kSXv37lWFChV03XXXOfrZbDbXVAkAAADAo5UqWNx+++0KDg7W3LlzVaVKFUlnH5r30EMP6ZZbbtHIkSNdWiQAAAAAz1aqayymTJmi+Ph4R6iQpCpVqmj8+PHcFQoAAAAoh0oVLDIyMvT7778Xak9LS9OJEycsFwUAAADAu5QqWPTp00cPPfSQ/vvf/+rw4cM6fPiw/vvf/2rQoEG66667XF0jAAAAAA9XqmDx1ltv6bbbbtOAAQNUu3Zt1a5dW/fdd5969OihGTNmuKy43NxcPf/886pbt64CAwN11VVX6aWXXnJ6joYxRnFxcYqOjlZgYKA6duyon3/+2WU1AAAAALi4Ul28XbFiRc2YMUOTJ0/WgQMHZIxR/fr1FRQU5NLiJk6cqLfeektz585V06ZNtWXLFj300EMKDQ3V0KFDJUmTJk3S1KlTNWfOHDVs2FDjx49X165dtWfPHgUHB7u0HsBb5eRkKSkpyaVjhoSEKCIiwqVjAgAA71WqYFEgJSVFKSkpat++vQIDA2WMcektZr/77jvdcccduu222yRJderU0fz587VlyxZJZ49WTJs2Tc8995zjFKy5c+cqKipKCQkJeuyxx1xWC+CtsrPTlZT0q4YMeUV2u91l44aF2ZWQMJNwAQAAJJUyWKSnp+uee+7RqlWrZLPZtG/fPl111VV65JFHVLlyZZfdGapdu3Z66623tHfvXjVs2FA//vij1q1bp2nTpkmSEhMTlZqaqm7dujnWsdvt6tChgzZs2FBssMjKylJWVpbjfUZGhkvqBTxRXt5J5eb6y99/uCpXbuiSMTMzk5WePkUZGRkECwAAIKmUwWL48OHy8/PToUOH1KRJE0d7v379NHz4cJcFi3/84x86fvy4GjdurAoVKigvL08vv/yy/va3v0mSUlNTJUlRUVFO60VFRV3wtI/4+Hi9+OKLLqkR8BYBATUVFFTPZeOdk80BAABKd/H28uXLNXHiRNWsWdOpvUGDBi49j/ujjz7SvHnzlJCQoG3btmnu3Ll69dVXNXfuXKd+559+dbFTssaOHavjx487XsnJyS6rGQAAACiPSnXE4tSpU6pYsWKh9j/++MOl53A/88wzGjNmjO69915JUvPmzZWUlKT4+HgNHDhQ1apVk3T2yEX16tUd66WlpRU6inEuu93u0joBAACA8q5URyzat2+v999/3/HeZrMpPz9fkydPVqdOnVxW3OnTp+Xj41xihQoVHLebrVu3rqpVq6YVK1Y4lmdnZ2vNmjVq27aty+oAAAAAcGGlOmIxefJkdezYUVu2bFF2drZGjx6tn3/+WX/++afWr1/vsuJuv/12vfzyy6pVq5aaNm2qH374QVOnTtXDDz8s6WygGTZsmCZMmKAGDRqoQYMGmjBhgipWrKj+/fu7rA4AAAAAF1aqYHH11Vfrp59+0syZM1WhQgWdOnVKd911l5588kmnU5Ksmj59ul544QUNHjxYaWlpio6O1mOPPaZ//vOfjj6jR49WZmamBg8erGPHjqlNmzZavnw5z7AAAAAALqMSB4ucnBx169ZNb7/9ttvvrBQcHKxp06Y5bi9bFJvNpri4OMXFxbm1FgAAAADFK/E1Fn5+ftq5c6dLH4QHAAAAwLuV6uLtBx54QLNmzXJ1LQAAAAC8VKmuscjOztZ//vMfrVixQq1bt1ZQUJDT8qlTp7qkOAAAAADeoUTB4tdff1WdOnW0c+dOXXfddZKkvXv3OvXhFCkAAACg/ClRsGjQoIFSUlK0atUqSVK/fv3073//+4IPowMAAABw5SvRNRbGGKf3X3zxhU6dOuXSggAAAAB4n1JdvF3g/KABAAAAoHwqUbCw2WyFrqHgmgoAAAAAJbrGwhijBx98UHa7XZJ05swZPf7444XuCrVo0SLXVQgAAADA45UoWAwcONDp/YABA1xaDAAAAADvVKJgMXv2bHfVAQAAAMCLWbp4GwAAAAAkggUAAAAAFyBYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAs8/hg8dtvv2nAgAEKCwtTxYoV1aJFC23dutWx3BijuLg4RUdHKzAwUB07dtTPP/9chhUDAAAA5Y9vWRdwIceOHdPNN9+sTp066YsvvlBkZKQOHDigypUrO/pMmjRJU6dO1Zw5c9SwYUONHz9eXbt21Z49exQcHFx2xQPwKEePHlVGRoZLxwwJCVFERIRLxwQAwFt5dLCYOHGiYmJiNHv2bEdbnTp1HH82xmjatGl67rnndNddd0mS5s6dq6ioKCUkJOixxx673CUD8EBHjx5V//5PKD09y6XjhoXZlZAwk3ABAIA8PFh8+umnuvXWW/X//X//n9asWaMaNWpo8ODB+vvf/y5JSkxMVGpqqrp16+ZYx263q0OHDtqwYUOxwSIrK0tZWf/3BcPV/4oJwLNkZGQoPT1LdvtIBQbGuGTMzMxkpadPUUZGBsECAAB5eLD49ddfNXPmTI0YMULPPvusNm3apKefflp2u10PPPCAUlNTJUlRUVFO60VFRSkpKanYcePj4/Xiiy+6tXYAnicwMEZBQfVcNl6Waw+AAADg1Tz64u38/Hxdd911mjBhglq2bKnHHntMf//73zVz5kynfjabzem9MaZQ27nGjh2r48ePO17JycluqR8AAAAoLzw6WFSvXl1XX321U1uTJk106NAhSVK1atUkyXHkokBaWlqhoxjnstvtCgkJcXoBAAAAKD2PDhY333yz9uzZ49S2d+9e1a5dW5JUt25dVatWTStWrHAsz87O1po1a9S2bdvLWisAAABQnnn0NRbDhw9X27ZtNWHCBN1zzz3atGmT3nnnHb3zzjuSzp4CNWzYME2YMEENGjRQgwYNNGHCBFWsWFH9+/cv4+qBK1tOTtYFr2UqrezsbPn7+7t0zKSkJOXm5rp0TAAA4Myjg8X111+vxYsXa+zYsXrppZdUt25dTZs2Tffdd5+jz+jRo5WZmanBgwfr2LFjatOmjZYvX84zLAA3ys5OV1LSrxoy5BXZ7XaXjZuTk6UjRxJVo0Z9+fq67tdTVtYpJSf/rtBQrrYGAMBdPDpYSFKvXr3Uq1evYpfbbDbFxcUpLi7u8hUFlHN5eSeVm+svf//hqly5ocvGPXZsozIzX1aFCk+7fNzc3JeVm5vnsjEBAIAzjw8WADxXQEBNl96+NTMzya3jAgAA9/Hoi7cBAAAAeAeCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALDMt6wLKIn4+Hg9++yzGjp0qKZNmyZJMsboxRdf1DvvvKNjx46pTZs2evPNN9W0adOyLRbAFS8nJ0tJSUkuHzckJEQREREuHxcAAHfymmCxefNmvfPOO7rmmmuc2idNmqSpU6dqzpw5atiwocaPH6+uXbtqz549Cg4OLqNqAVzpsrPTlZT0q4YMeUV2u92lY4eF2ZWQMJNwAQDwKl4RLE6ePKn77rtP7777rsaPH+9oN8Zo2rRpeu6553TXXXdJkubOnauoqCglJCToscceK6uSAVzh8vJOKjfXX/7+w1W5ckOXjZuZmaz09CnKyMggWAAAvIpXBIsnn3xSt912m7p06eIULBITE5Wamqpu3bo52ux2uzp06KANGzYQLAC4XUBATQUF1XPpmFlZLh0OAIDLwuODxYIFC7Rt2zZt3ry50LLU1FRJUlRUlFN7VFTUBc97zsrKUtY5f3NnZGS4qFoAAACgfPLou0IlJydr6NChmjdvngICAortZ7PZnN4bYwq1nSs+Pl6hoaGOV0xMjMtqBgAAAMojjw4WW7duVVpamlq1aiVfX1/5+vpqzZo1+ve//y1fX1/HkYqCIxcF0tLSCh3FONfYsWN1/Phxxys5Odmt+wEAAABc6Tz6VKjY2Fjt2LHDqe2hhx5S48aN9Y9//ENXXXWVqlWrphUrVqhly5aSpOzsbK1Zs0YTJ04sdly73e7yu7gAAAAA5ZlHB4vg4GA1a9bMqS0oKEhhYWGO9mHDhmnChAlq0KCBGjRooAkTJqhixYrq379/WZQMAAAAlEseHSwuxejRo5WZmanBgwc7HpC3fPlynmEBAAAAXEZeFyxWr17t9N5msykuLk5xcXFlUg8AAAAAD794GwAAAIB3IFgAAAAAsIxgAQAAAMAyr7vGAgCudDk5WUpKSnL5uCEhIYqIiHD5uAAASAQLAPAo2dnpSkr6VUOGvOLy5+2EhdmVkDCTcAEAcAuCBQB4kLy8k8rN9Ze//3BVrtzQZeNmZiYrPX2KMjIyCBYAALcgWACABwoIqKmgoHouHTMry6XDAQDghIu3AQAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYJlvWRcAALg8cnKylJSU5NIxQ0JCFBER4dIxAQDeiWABAOVAdna6kpJ+1ZAhr8hut7ts3LAwuxISZhIuAAAECwAoD/LyTio311/+/sNVuXJDl4yZmZms9PQpysjIIFgAAAgWAFCeBATUVFBQPZeNl5XlsqEAAF6Oi7cBAAAAWEawAAAAAGAZp0IBAErNHXeakrjbFAB4I4IFAKBU3HWnKYm7TQGANyJYAABKxR13mpK42xQAeCuCBQDAElffaUriblMA4I24eBsAAACAZQQLAAAAAJYRLAAAAABY5tHBIj4+Xtdff72Cg4MVGRmpO++8U3v27HHqY4xRXFycoqOjFRgYqI4dO+rnn38uo4oBAACA8smjg8WaNWv05JNPauPGjVqxYoVyc3PVrVs3nTp1ytFn0qRJmjp1qt544w1t3rxZ1apVU9euXXXixIkyrBwAAAAoXzz6rlBffvml0/vZs2crMjJSW7duVfv27WWM0bRp0/Tcc8/prrvukiTNnTtXUVFRSkhI0GOPPVYWZQMAAADljkcfsTjf8ePHJUlVq1aVJCUmJio1NVXdunVz9LHb7erQoYM2bNhQ7DhZWVnKyMhwegEAAAAoPa8JFsYYjRgxQu3atVOzZs0kSampqZKkqKgop75RUVGOZUWJj49XaGio4xUTE+O+wgEAAIBywGuCxVNPPaWffvpJ8+fPL7TMZrM5vTfGFGo719ixY3X8+HHHKzk52eX1AgAAAOWJR19jUWDIkCH69NNP9e2336pmzZqO9mrVqkk6e+SievXqjva0tLRCRzHOZbfbZbfb3VcwAAAAUM54dLAwxmjIkCFavHixVq9erbp16zotr1u3rqpVq6YVK1aoZcuWkqTs7GytWbNGEydOLIuSAQDlzNGjR91yrV5ISIgiIiJcPi4AuItHB4snn3xSCQkJ+t///qfg4GDHdROhoaEKDAyUzWbTsGHDNGHCBDVo0EANGjTQhAkTVLFiRfXv37+MqwcAXOmOHj2q/v2fUHp6lsvHDguzKyFhJuECgNfw6GAxc+ZMSVLHjh2d2mfPnq0HH3xQkjR69GhlZmZq8ODBOnbsmNq0aaPly5crODj4MlcLAChvMjIylJ6eJbt9pAIDXXcjkMzMZKWnT1FGRgbBAoDX8OhgYYy5aB+bzaa4uDjFxcW5vyAAAIoQGBijoKB6Lh0zy/UHQQDArbzmrlAAAAAAPBfBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUefbtZAED5lJOTpaSkJJePm52dLX9/f5eNl5SUpNzcXJeNBwDejGABAPAo2dnpSkr6VUOGvCK73e6ycXNysnTkSKJq1KgvX1/X/PWXlXVKycm/KzSUh04AAMECAOBR8vJOKjfXX/7+w1W5ckOXjXvs2EZlZr6sChWedtm4x45tVG7uy8rNzXPJeADgzQgWAACPFBBQ06VPs87MTHL5uAVjAgC4eBsAAACACxAsAAAAAFhGsAAAAABgGcECAAAAgGVcvA0AgAdy17M8QkJCFBER4fJxAYBgAQCAh3HXszwkKSzMroSEmYQLAC5HsAAAwMO461kemZnJSk+fooyMDJcGi6NHjyojI8Nl4xXg6ArgXQgWAAB4KFc/y0OSslz8kPCjR4+qf/8nlJ7u+qePc3QF8C4ECwAAyhFXX7uRlJSk338/paCgfygwMMZl47rr6AoA9yFYAABQTrjj2o2srFNKTv5d114b6fFHVwC4F8ECAIBywh3Xbhw7tlG5uS8rNzfPJeMB8F4ECwAAyhlXXruRmen6W+IC8E4ECwAAUG5wByvAfQgWAACgXOAOVoB7ESwAAEC5kJGRofT0LNntI7mDFeAGBAsAAFCuBAbGcAcrwA0IFgAAwCO545kbubm5LhvvXK6utQDXbsCbECwAAIDHceczN0JDXXt4wR21FuDaDXgTggUAAPA43vTMDXfUKp29diM1dYJ27Nih2rVru2zc7Oxs+fv7u2y8AhxdwRUTLGbMmKHJkycrJSVFTZs21bRp03TLLbeUdVkAAMACb3rmhitrldxzJCQnJ0tHjiSqRo368vV17ddAjq7giggWH330kYYNG6YZM2bo5ptv1ttvv60ePXrol19+Ua1atcq6PAAAgBJz11GbzMyXVaHC0y4/usKdsXhOyhURLKZOnapBgwbpkUcekSRNmzZNX331lWbOnKn4+Pgyrg4AAKD03HHUxtVHVyTujMVzUq6AYJGdna2tW7dqzJgxTu3dunXThg0byqgqAAAAlCc8J+UKCBZ//PGH8vLyFBUV5dQeFRWl1NTUItfJyspS1jmx+vjx45LklkNXl+LEiRPKy8vRiRO7lZt7wmXjnjp1QMbk6dSpvfLzc92Fau4Y15tqdde41Opd43pTre4a15tqdde43lSru8alVu8a1121Zmb+pqys0/rll1904oTrvst4k+TkZGVlnVGFCqdc+n0uN/fU//ueeKJMvqsWbNMYc/HOxsv99ttvRpLZsGGDU/v48eNNo0aNilxn3LhxRhIvXrx48eLFixcvXrwu4ZWcnHzR7+Vef8QiPDxcFSpUKHR0Ii0trdBRjAJjx47ViBEjHO/z8/P1559/KiwsTDabza31FiUjI0MxMTFKTk5WSEjIZd9+ecAcuxfz617Mr3sxv+7HHLsX8+te5X1+jTE6ceKEoqOjL9rX64OFv7+/WrVqpRUrVqhPnz6O9hUrVuiOO+4och273V7otm2VK1d2Z5mXJCQkpFx+YC8n5ti9mF/3Yn7di/l1P+bYvZhf9yrP8xsaGnpJ/bw+WEjSiBEjdP/996t169a66aab9M477+jQoUN6/PHHy7o0AAAAoFy4IoJFv379lJ6erpdeekkpKSlq1qyZPv/8c5c+pRIAAABA8a6IYCFJgwcP1uDBg8u6jFKx2+0aN26cy56qicKYY/dift2L+XUv5tf9mGP3Yn7di/m9dDZjLuXeUQAAAABQPJ+yLgAAAACA9yNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMt+yLsAT5Ofn68iRIwoODpbNZivrcgAAAACPYIzRiRMnFB0dLR+fCx+TIFhIOnLkiGJiYsq6DAAAAMAjJScnq2bNmhfsQ7CQFBwcLOnshIWEhJRxNQAAAIBnyMjIUExMjOP78oUQLCTH6U8hISEECwAAAOA8l3K5ABdvAwAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAAAAALCMYAEAAADAMoIFAAAAAMsIFgAAAAAsI1gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLfMu6AFwZDh06pD/++KOsy4AXCQ8PV61atcq6DAAA4CIEC1h26NAhNWncSKczz5R1KfAiFQMDtGv3HsIFAABXCIIFLPvjjz90OvOM5g2WmkSXdTXuseuINGCGruh9vJzOzucZ/fHHHwQLAACuEAQLuEyTaOm6umVdhXuVh30EAAAoDS7eBgAAAGAZRyw8wOnTp7V79241btxYFStWLOtyAABe4Ny/O+x2u9auXavffvtNR48eVUREhGrUqKFbbrlFkrR27VqlpKSoevXquuWWW1ShQgWnsbKzszV9+nStXbtWp06d0nXXXafIyEhFRkYqPT3dabyCdfPy8py2GRoaqk8//VSnTp3SVVddpdq1a2vTpk2qVKmS7r//fsXGxhba7vkKxiyotW3bttqwYUORtZ/ft6j9Km7c8/sWtVySVq9erW+++UaHDh1SrVq11LlzZ3Xs2FEVKlS4pO2f2ycyMlKSlJaWdkn9L7RPl6OfdPHPDdyvJJ9zT0Cw8AC7d+9Wq1attHXrVl133XVlXQ4AwAsU/N0xefJkvfnmmzp48GChPhEREbLZbEpLS3O01alTR1OmTNFdd90lSRo9erSmTJmi/Px8R5+VK1cWuc2CdSVp5MiRRW6zKPPmzVNISIhmz57t2O75Fi1aVGhMX19f5ebmXtL2z9+vC417bt+ilkdERCg7O1vHjx93GmvChAmKjIzUwIED9cknn1xw+0WNe65L6V/UPl2OfpGRkTLG6OjRoxdcF+51qT9DT8KpUAAAeLHRo0crPDxcktSjRw+9++676tGjh2w2m44ePaq0tDTFx8frxIkT+u6779S8eXPdfffdWrRokUaPHq3Jkyc7QkX9+vUlqdC/iLZs2VLS2dtE9+3bV3fffbdjmwX/Em+z2Yqsr3nz5qpataoyMjLUt29fLVq0qFCfRYsW6e6771bz5s313Xffad68eZKksLAw2Ww2zZs3z6n2vn37OvoWtV/FjXt+39GjRxdaHh8fr6NHjzpCxU033aTp06frpptuknT2iMPkyZMVHh5e7PbP3W58fLwkqV27dmrXrp1sNpvi4+OL7X+hfboc/eLj45WWlqajR48W+7mB+13qz9DT2IwxpqyLKGsZGRkKDQ3V8ePHFRISctm3v23bNq8+YuGof/yVe2HztkSp1fO6ovfxcnLMp5d+5gFPsHnzZt1www265ZZbdOjQIV1zzTVasmSJfHx8lJOTo9DQUNlsNnXq1Em//PKL9u3bpwoVKig/P1933nmnfvrpJx0+fFjGGPn7+ys2NlY7d+5U8+bNtWPHDqWkpCgnJ0d2u13Vq1dX06ZNtWPHDqWlpclmsyk8PFzNmjXT559/Ln9/fx09elSVK1eWMUYREREKCgrSb7/9ppycHGVkZKhBgwZKS0tT7dq1tX//fqdTmurXr6/mzZtryZIlMsY43i9atEh33XWXdu7cqX379ik/P9+xX3/99Zf8/Pwc81GwXwV9JTmN6+Pj49T3jjvu0Jdffqnu3bvrf//7n3x8fBy1pKamKjs7WwEBAY7t5Ofnq3fv3lq2bJl8fHxUu3Ztx5yeu/0dO3ZIOhuoFi5cqIYNGzpqkOSocc+ePerbt69T/6LqLOi/e/duNWrUyK39Cva/WbNmkqSff/650OemYH49+XQcb3f+/xPF/Qwv18+hJN+TORXKA2RmZkqSdu3aVcaVlE5B3ZnZZVwIvEbBZ8VbP/OAJyj4otq6dWutXbtWCxYscHwBWb9+vePvlh49emjZsmVau3atOnbsKB8fH40dO1Zt27Z1jHXmzBn17NlTy5Yt0+jRo7V06VL94x//0MSJE3XmzBklJiZq5MiRWrp0qWOdQ4cO6frrr5ckjRgxQu+9954K/q3ygQce0JQpU3TvvfdqwYIFGjt2rF566SU99thjOnjwoKMW6ex5/AcPHtT8+fPl4+Oj1atXO977+vo6al27dq2k//s7c/369Y4xJDntV0Hfc8c9l4+Pj7p3766lS5eqR48ejuUFtRQ4ffq0Yzs+Pj6OuczPz1diYqLTfpw/r/Pnz9f69esL1VDQZ/369YX6F1VnQZ8ZM2ZccH9c0e/cn4UxxjGX539uzt1vuN75/0+cy9N/DgQLD1DwS2zAgAFlW4hFB/+Qbm5U1lXAGxz8fw9p9/bPPOAJTp48KUmOf2WWpJSUFMefAwMDC7Wd2/f8fgX/HTRokCZOnFho+bmOHTsmSXrkkUc0bdo0R/tVV10lSbr++uu1YMEC7du3T88++2yR9RX8uaCm89+f317UGOfv18X2taj9LW7MouayuP7nbqtZs2b67LPPimwvWLdXr14XrbOg/cCBA27vd+7cF4TEouayqHmC65z//8D5PPnnQLDwAHXq1JF09uK2Jk2alG0xpbBr1y4NGDBAdcLLuhJ4i4LPird+5gFPsHDhQk2YMEGVKlWSJO3cuVM33nijJKl69eqOfgX/wn9u286dOwuNV9Cv4L+zZs0qcvm5qlSpIkn6z3/+o3r16jnaf/31V0lnT9eSpAYNGjgd7Ti3loI/F9R//vuCWs9dp6j35+7X+ftaMC8X2t/ixixqLovrf+687ty5s9C+nF/j+f2LqrOgT8H8urPfufUWBIuiPjdFzRNcp6jPzbk8+efANRbiGguruMYCJcU1FoB1XGPBNRau7sc1Fp7Bm6+x4K5QAAB4oYIvFOvWrVNERIQ+++wz9erVS++8847uuOMOnTlzRqdPn9ayZcv097//XadPn9Z3332nO++8U0uXLtXUqVM1YsQI5efn68yZM1q2bJn8/Py0dOlSHT58WNnZ2TLG6MyZM6pcubKWLl2qiIgIZWZmKjMzU5GRkfr8888VGRmp7OxsR6iQpKNHj+rgwYPKyclRs2bNVLt2bf3+++8yxmjKlClOX4YqVKigKVOmaOnSpbrzzju1adMmjR8/Xp999plq1qyppUuX6l//+pc2bdqkvn37Ovarb9++TnfLKdivV199VRUqVCg07vl9ly1bpuHDh2vZsmWO5adPn9ajjz6qM2fOKD8/X6dPn1b79u3173//WzfffLOWLVsm6eyXu7CwMG3atKnQ9qdMmeLYbt++ffXoo4/qs88+U/v27dWhQwctXbpUf//739W3b99C/Yuqs2Cf/P393d6vYP+XLl3qqPP8z03B/MJ9LvbZ9eSfA0csxBELqzhigZLiiAVgXcHv3gs9x+Lch7IVqFu3rl599dULPseiOAXrSiV7joUklzzH4kLbP3+/LjTuuX2Le45DVlZWoedYFCwr6jkW52//Ys+xuJT+Re3T5ehX1HMsiptfuM+l/gzdrSTfkwkWIlhYRbBASREsAOvO/bvj2muv5cnbPHnbpf0knrztCTzhydsEixIq62Bx+vRp7d69W40bN1bFihUv+/atIligpAgWgHXe/ncHAO/Acyy8TMWKFflyBQAoEf7uAOBpCBZwmV1HyroC9ynYtyt5Hy8n5hEAgCsPwQKWhYeHq2JggAbMOFPWpbjdgBllXcGVo2JggMLDefgJAABXCoIFLKtVq5Z27d6jP/74o6xLgRcJDw9XrVq1yroMAADgIgQLuEStWrX4kggAAFCO8YA8AAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlhEsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZb5lXYAnMMZIkjIyMsq4EgAAAMBzFHw/Lvi+fCEEC0knTpyQJMXExJRxJQAAAIDnOXHihEJDQy/Yx2YuJX5c4fLz83XkyBEFBwfLZrNd9u1nZGQoJiZGycnJCgkJuezbLw+YY/dift2L+XUv5tf9mGP3Yn7dq7zPrzFGJ06cUHR0tHx8LnwVBUcsJPn4+KhmzZplXYZCQkLK5Qf2cmKO3Yv5dS/m172YX/djjt2L+XWv8jy/FztSUYCLtwEAAABYRrAAAAAAYBnBwgPY7XaNGzdOdru9rEu5YjHH7sX8uhfz617Mr/sxx+7F/LoX83vpuHgbAAAAgGUcsQAAAABgGcECAAAAgGUECwAAAACWESwukxkzZqhu3boKCAhQq1attHbt2gv2X7NmjVq1aqWAgABdddVVeuutty5Tpd6pJPObkpKi/v37q1GjRvLx8dGwYcMuX6FerCRzvGjRInXt2lUREREKCQnRTTfdpK+++uoyVut9SjK/69at080336ywsDAFBgaqcePGeu211y5jtd6npL+DC6xfv16+vr5q0aKFewv0ciWZ39WrV8tmsxV67d69+zJW7H1K+hnOysrSc889p9q1a8tut6tevXp67733LlO13qck8/vggw8W+Rlu2rTpZazYQxm43YIFC4yfn5959913zS+//GKGDh1qgoKCTFJSUpH9f/31V1OxYkUzdOhQ88svv5h3333X+Pn5mf/+97+XuXLvUNL5TUxMNE8//bSZO3euadGihRk6dOjlLdgLlXSOhw4daiZOnGg2bdpk9u7da8aOHWv8/PzMtm3bLnPl3qGk87tt2zaTkJBgdu7caRITE80HH3xgKlasaN5+++3LXLl3KOn8Fvjrr7/MVVddZbp162auvfbay1OsFyrp/K5atcpIMnv27DEpKSmOV25u7mWu3HuU5jPcu3dv06ZNG7NixQqTmJhovv/+e7N+/frLWLX3KOn8/vXXX06f3eTkZFO1alUzbty4y1u4ByJYXAY33HCDefzxx53aGjdubMaMGVNk/9GjR5vGjRs7tT322GPmxhtvdFuN3qyk83uuDh06ECwugZU5LnD11VebF1980dWlXRFcMb99+vQxAwYMcHVpV4TSzm+/fv3M888/b8aNG0ewuICSzm9BsDh27NhlqO7KUNI5/uKLL0xoaKhJT0+/HOV5Pau/gxcvXmxsNps5ePCgO8rzKpwK5WbZ2dnaunWrunXr5tTerVs3bdiwoch1vvvuu0L9b731Vm3ZskU5OTluq9UblWZ+UTKumOP8/HydOHFCVatWdUeJXs0V8/vDDz9ow4YN6tChgztK9Gqlnd/Zs2frwIEDGjdunLtL9GpWPr8tW7ZU9erVFRsbq1WrVrmzTK9Wmjn+9NNP1bp1a02aNEk1atRQw4YNNWrUKGVmZl6Okr2KK34Hz5o1S126dFHt2rXdUaJX8S3rAq50f/zxh/Ly8hQVFeXUHhUVpdTU1CLXSU1NLbJ/bm6u/vjjD1WvXt1t9Xqb0swvSsYVczxlyhSdOnVK99xzjztK9GpW5rdmzZo6evSocnNzFRcXp0ceecSdpXql0szvvn37NGbMGK1du1a+vvw1eSGlmd/q1avrnXfeUatWrZSVlaUPPvhAsbGxWr16tdq3b385yvYqpZnjX3/9VevWrVNAQIAWL16sP/74Q4MHD9aff/7JdRbnsfp3XEpKir744gslJCS4q0Svwm/My8Rmszm9N8YUartY/6LacVZJ5xclV9o5nj9/vuLi4vS///1PkZGR7irP65VmfteuXauTJ09q48aNGjNmjOrXr6+//e1v7izTa13q/Obl5al///568cUX1bBhw8tVntcryee3UaNGatSokeP9TTfdpOTkZL366qsEiwsoyRzn5+fLZrPpww8/VGhoqCRp6tSpuvvuu/Xmm28qMDDQ7fV6m9L+HTdnzhxVrlxZd955p5sq8y4ECzcLDw9XhQoVCqXetLS0Qum4QLVq1Yrs7+vrq7CwMLfV6o1KM78oGStz/NFHH2nQoEH65JNP1KVLF3eW6bWszG/dunUlSc2bN9fvv/+uuLg4gsV5Sjq/J06c0JYtW/TDDz/oqaeeknT2S5oxRr6+vlq+fLk6d+58WWr3Bq76HXzjjTdq3rx5ri7vilCaOa5evbpq1KjhCBWS1KRJExljdPjwYTVo0MCtNXsTK59hY4zee+893X///fL393dnmV6DayzczN/fX61atdKKFSuc2lesWKG2bdsWuc5NN91UqP/y5cvVunVr+fn5ua1Wb1Sa+UXJlHaO58+frwcffFAJCQm67bbb3F2m13LVZ9gYo6ysLFeX5/VKOr8hISHasWOHtm/f7ng9/vjjatSokbZv3642bdpcrtK9gqs+vz/88AOn+RajNHN8880368iRIzp58qSjbe/evfLx8VHNmjXdWq+3sfIZXrNmjfbv369Bgwa5s0TvUiaXjJczBbcxmzVrlvnll1/MsGHDTFBQkOPuAWPGjDH333+/o3/B7WaHDx9ufvnlFzNr1ixuN3sBJZ1fY4z54YcfzA8//GBatWpl+vfvb3744Qfz888/l0X5XqGkc5yQkGB8fX3Nm2++6XRLvr/++qusdsGjlXR+33jjDfPpp5+avXv3mr1795r33nvPhISEmOeee66sdsGjleZ3xLm4K9SFlXR+X3vtNbN48WKzd+9es3PnTjNmzBgjySxcuLCsdsHjlXSOT5w4YWrWrGnuvvtu8/PPP5s1a9aYBg0amEceeaSsdsGjlfZ3xIABA0ybNm0ud7kejWBxmbz55pumdu3axt/f31x33XVmzZo1jmUDBw40HTp0cOq/evVq07JlS+Pv72/q1KljZs6ceZkr9i4lnV9JhV61a9e+vEV7mZLMcYcOHYqc44EDB17+wr1ESeb33//+t2natKmpWLGiCQkJMS1btjQzZswweXl5ZVC5dyjp74hzESwuriTzO3HiRFOvXj0TEBBgqlSpYtq1a2eWLVtWBlV7l5J+hnft2mW6dOliAgMDTc2aNc2IESPM6dOnL3PV3qOk8/vXX3+ZwMBA884771zmSj2bzZj/d1UwAAAAAJQS11gAAAAAsIxgAQAAAMAyggUAAAAAywgWAAAAACwjWAAAAACwjGABAAAAwDKCBQAAAADLCBYAAAAALCNYAIAXWb16tWw2m/766y+3baNjx44aNmyY28YvqfPrqVOnjqZNm+Z4n5qaqq5duyooKEiVK1cutg0A4F4ECwDwMBs2bFCFChXUvXv3si7lkhw8eFA2m03bt2+/LNvbvHmzHn30Ucf71157TSkpKdq+fbv27t1bbBsAwL0IFgDgYd577z0NGTJE69at06FDh8q6HI8TERGhihUrOt4fOHBArVq1UoMGDRQZGVlsW0nl5OS4pF4AKC8IFgDgQU6dOqWPP/5YTzzxhHr16qU5c+YU2W/9+vW69tprFRAQoDZt2mjHjh2OZUlJSbr99ttVpUoVBQUFqWnTpvr8888dy9esWaMbbrhBdrtd1atX15gxY5Sbm1tsTTabTUuWLHFqq1y5sqO2unXrSpJatmwpm82mjh07OvrNnj1bTZo0UUBAgBo3bqwZM2ZcdP8feOABVapUSdWrV9eUKVMK9Tn3VKg6depo4cKFev/992Wz2fTggw8W2SZJx48f16OPPqrIyEiFhISoc+fO+vHHHx3jxsXFqUWLFnrvvfd01VVXyW63yxhzyet98MEHqlOnjkJDQ3XvvffqxIkTjj75+fmaOHGi6tevL7vdrlq1aunll192LP/tt9/Ur18/ValSRWFhYbrjjjt08ODBC84VAHgaggUAeJCPPvpIjRo1UqNGjTRgwADNnj1bxphC/Z555hm9+uqr2rx5syIjI9W7d2/Hv7A/+eSTysrK0rfffqsdO3Zo4sSJqlSpkqSzX2B79uyp66+/Xj/++KNmzpypWbNmafz48aWuedOmTZKklStXKiUlRYsWLZIkvfvuu3ruuef08ssva9euXZowYYJeeOEFzZ07t9ixnnnmGa1atUqLFy/W8uXLtXr1am3durXY/ps3b1b37t11zz33KCUlRa+//nqRbcYY3XbbbUpNTdXnn3+urVu36rrrrlNsbKz+/PNPx3j79+/Xxx9/rIULFzpO7bqU9Q4cOKAlS5Zo6dKlWrp0qdasWaNXXnnFsXzs2LGaOHGiXnjhBf3yyy9KSEhQVFSUJOn06dPq1KmTKlWqpG+//Vbr1q1TpUqV1L17d2VnZ5f8BwIAZcUAADxG27ZtzbRp04wxxuTk5Jjw8HCzYsUKx/JVq1YZSWbBggWOtvT0dBMYGGg++ugjY4wxzZs3N3FxcUWO/+yzz5pGjRqZ/Px8R9ubb75pKlWqZPLy8owxxnTo0MEMHTrUsVySWbx4sdM4oaGhZvbs2cYYYxITE40k88MPPzj1iYmJMQkJCU5t//rXv8xNN91UZG0nTpww/v7+Re7bufXUrl3bvPbaa473d9xxhxk4cKDTWOe3ff311yYkJMScOXPGqV+9evXM22+/bYwxZty4ccbPz8+kpaWVeL2KFSuajIwMx/JnnnnGtGnTxhhjTEZGhrHb7ebdd98tcr9nzZpV6GeSlZVlAgMDzVdffVXkOgDgiXzLONcAAP6fPXv2aNOmTY5/8ff19VW/fv303nvvqUuXLk59b7rpJsefq1atqkaNGmnXrl2SpKefflpPPPGEli9fri5duqhv37665pprJEm7du3STTfdJJvN5lj/5ptv1smTJ3X48GHVqlXLJfty9OhRJScna9CgQfr73//uaM/NzVVoaGiR6xw4cEDZ2dlF7ptVW7du1cmTJxUWFubUnpmZqQMHDjje165dWxERESVer06dOgoODna8r169utLS0iSdnfOsrCzFxsYWW9v+/fud1pekM2fOOG0DADwdwQIAPMSsWbOUm5urGjVqONqMMfLz89OxY8dUpUqVC65fEBYeeeQR3XrrrVq2bJmWL1+u+Ph4TZkyRUOGDJExxilUFGzj3PWLGtecdzrWxS5szs/Pl3T2dKg2bdo4LatQoUKR65y/DVfKz89X9erVtXr16kLLzr0dbVBQUKnW8/Pzc1pms9kccxAYGHjR2lq1aqUPP/yw0LJzQw4AeDqCBQB4gNzcXL3//vuaMmWKunXr5rSsb9+++vDDD/XUU0852jZu3Og4unDs2DHt3btXjRs3diyPiYnR448/rscff1xjx47Vu+++qyFDhujqq6/WwoULnQLGhg0bFBwc7BRozhUREaGUlBTH+3379un06dOO9/7+/pKkvLw8R1tUVJRq1KihX3/9Vffdd98lzUH9+vXl5+dX5L516NDhksYoznXXXafU1FT5+vqqTp06bl/vXA0aNFBgYKC+/vprPfLII0Vu46OPPnJcHA4A3oqLtwHAAyxdulTHjh3ToEGD1KxZM6fX3XffrVmzZjn1f+mll/T1119r586devDBBxUeHq4777xTkjRs2DB99dVXSkxM1LZt2/TNN9+oSZMmkqTBgwcrOTlZQ4YM0e7du/W///1P48aN04gRI+TjU/RfCZ07d9Ybb7yhbdu2acuWLXr88ced/oU+MjJSgYGB+vLLL/X777/r+PHjks7eLSk+Pl6vv/669u7dqx07dmj27NmaOnVqkdupVKmSBg0apGeeecZp34qrqyS6dOmim266SXfeeae++uorHTx4UBs2bNDzzz+vLVu2uHy9cwUEBOgf//iHRo8erffff18HDhzQxo0bHT/T++67T+Hh4brjjju0du1aJSYmas2aNRo6dKgOHz5sed8B4HIhWACAB5g1a5a6dOlS5PUHffv21fbt27Vt2zZH2yuvvKKhQ4eqVatWSklJ0aeffup05ODJJ59UkyZN1L17dzVq1Mhxm9caNWro888/16ZNm3Tttdfq8ccf16BBg/T8888XW9uUKVMUExOj9u3bq3///ho1apTTcyR8fX3173//W2+//baio6N1xx13SDp7StZ//vMfzZkzR82bN1eHDh00Z84cx+1pizJ58mS1b99evXv3VpcuXdSuXTu1atWqZJNZBJvNps8//1zt27fXww8/rIYNG+ree+/VwYMHHXdncuV653vhhRc0cuRI/fOf/1STJk3Ur18/xzUYFStW1LfffqtatWrprrvuUpMmTfTwww8rMzOTIxgAvIrNuPOkVgAAAADlAkcsAAAAAFhGsAAAAABgGcECAAAAgGUECwAAAACWESwAAAAAWEawAAAAAGAZwQIAAACAZQQLAAAAAJYRLAAAAABYRrAAAAAAYBnBAgAAAIBlBAsAAAAAlv3/2+f5WtPvp1QAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure with two subplots\n",
    "fig, (ax_hist, ax_box) = plt.subplots(\n",
    "    nrows=2, sharex=True, gridspec_kw={\"height_ratios\": (3, 1)}, figsize=(8, 6)\n",
    ")\n",
    "\n",
    "# Plot histogram\n",
    "ax_hist.hist(similarity_diff, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax_hist.set_ylabel('Frequency')\n",
    "\n",
    "# Plot boxplot\n",
    "ax_box.boxplot(similarity_diff, vert=False, patch_artist=True,\n",
    "               boxprops=dict(facecolor='orange', color='black'),\n",
    "               medianprops=dict(color='black'))\n",
    "ax_box.set_xlabel('Absolute difference')\n",
    "ax_box.yaxis.set_visible(False)\n",
    "\n",
    "# Set title and adjust layout\n",
    "ax_hist.set_title('Histogram with Boxplot Below')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different LLO Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "llo_results = Path(\"results_LLO_threshold\")\n",
    "\n",
    "threshold_files = llo_results.glob(\"*.json\")\n",
    "\n",
    "llo_rows = []\n",
    "for experiment in threshold_files:\n",
    "    experiment = ExperimentResult(load_json_file(experiment))\n",
    "    args = experiment.args\n",
    "    short_model_name = find_arg(args, \"model_name\")\n",
    "    dataset = find_arg(args, \"c_task\")\n",
    "    n_samples = find_arg(args, \"number_of_samples\")\n",
    "    llo_threshold = experiment.llo_threshold\n",
    "\n",
    "    assert n_samples == len(experiment.examples_names()), \"Number of samples from args is different than actual number of samples\"\n",
    "\n",
    "    for test in experiment.tests:\n",
    "        variable_name = TEST_TO_VARIABLE_NAME[test]\n",
    "        test_results = experiment.get_variable(variable_name)\n",
    "\n",
    "        # The \"atanasova_input_from_expl\" keeps a counter and not 0 or 1\n",
    "        # per sample\n",
    "        if test == \"atanasova_input_from_expl\":\n",
    "            test_results = cumsum_to_differences(test_results)\n",
    "\n",
    "        mean = np.mean(test_results)\n",
    "        std = np.std(test_results)\n",
    "        min_val = np.min(test_results)\n",
    "        max_val = np.max(test_results)\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": short_model_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_samples\": n_samples,\n",
    "            \"llo_threshold\": llo_threshold,\n",
    "            \"test\": test,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "        }\n",
    "        llo_rows.append(new_row)\n",
    "\n",
    "llo_results_dataframe = pd.DataFrame(llo_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>llo_threshold</th>\n",
       "      <th>test</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.178989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.172534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.172145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model dataset  n_samples  llo_threshold         test    mean       std  \\\n",
       "14  gpt2   comve          1           0.10  loo-posthoc  0.0000  0.000000   \n",
       "20  gpt2   comve          1           0.20  loo-posthoc  0.0000  0.000000   \n",
       "0   gpt2   comve          1           0.30  loo-posthoc  0.0000  0.000000   \n",
       "11  gpt2   comve          1           0.40  loo-posthoc  0.0000  0.000000   \n",
       "21  gpt2   comve          1           0.50  loo-posthoc  0.0000  0.000000   \n",
       "7   gpt2   comve          1           0.60  loo-posthoc  0.0000  0.000000   \n",
       "12  gpt2   comve          1           0.70  loo-posthoc  0.0000  0.000000   \n",
       "6   gpt2   comve          1           0.80  loo-posthoc  0.0000  0.000000   \n",
       "10  gpt2   comve          1           0.90  loo-posthoc  0.2500  0.000000   \n",
       "17  gpt2   comve          1           0.99  loo-posthoc  0.1800  0.000000   \n",
       "9   gpt2   comve          5           0.20  loo-posthoc  0.0000  0.000000   \n",
       "16  gpt2   comve          5           0.40  loo-posthoc  0.0000  0.000000   \n",
       "2   gpt2   comve          5           0.50  loo-posthoc  0.0000  0.000000   \n",
       "1   gpt2   comve          5           0.60  loo-posthoc  0.0300  0.060000   \n",
       "19  gpt2   comve          5           0.80  loo-posthoc  0.1340  0.136323   \n",
       "3   gpt2   comve          5           1.00  loo-posthoc  0.2980  0.069685   \n",
       "18  gpt2   comve         50           0.20  loo-posthoc  0.0100  0.070000   \n",
       "15  gpt2   comve         50           0.40  loo-posthoc  0.0730  0.178989   \n",
       "5   gpt2   comve         50           0.50  loo-posthoc  0.0860  0.172534   \n",
       "13  gpt2   comve         50           0.60  loo-posthoc  0.0978  0.176298   \n",
       "4   gpt2   comve         50           0.80  loo-posthoc  0.1702  0.172145   \n",
       "8   gpt2   comve         50           1.00  loo-posthoc  0.2724  0.058431   \n",
       "\n",
       "     min   max  \n",
       "14  0.00  0.00  \n",
       "20  0.00  0.00  \n",
       "0   0.00  0.00  \n",
       "11  0.00  0.00  \n",
       "21  0.00  0.00  \n",
       "7   0.00  0.00  \n",
       "12  0.00  0.00  \n",
       "6   0.00  0.00  \n",
       "10  0.25  0.25  \n",
       "17  0.18  0.18  \n",
       "9   0.00  0.00  \n",
       "16  0.00  0.00  \n",
       "2   0.00  0.00  \n",
       "1   0.00  0.15  \n",
       "19  0.00  0.37  \n",
       "3   0.23  0.42  \n",
       "18  0.00  0.50  \n",
       "15  0.00  0.71  \n",
       "5   0.00  0.58  \n",
       "13  0.00  0.71  \n",
       "4   0.00  0.55  \n",
       "8   0.16  0.43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(llo_results_dataframe.sort_values([\"n_samples\", \"llo_threshold\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
