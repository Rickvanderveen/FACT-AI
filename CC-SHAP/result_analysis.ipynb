{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSON file and return its contents as a dictionary.\n",
    "\n",
    "    :param file_path: Path to the JSON file.\n",
    "    :return: Parsed JSON content as a dictionary.\n",
    "    :raises: FileNotFoundError, json.JSONDecodeError\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{file_path}' does not exist.\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Failed to decode JSON from file '{file_path}'.\")\n",
    "        print(f\"Details: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResult:\n",
    "    def __init__(self, results_json: dict):\n",
    "        self.results_json = results_json\n",
    "    \n",
    "    @property\n",
    "    def args(self):\n",
    "        return self.results_json[\"args\"]\n",
    "    \n",
    "    @property\n",
    "    def model(self) -> dict:\n",
    "        return self.results_json[\"model\"]\n",
    "    \n",
    "    @property\n",
    "    def examples(self) -> dict:\n",
    "        return self.results_json[\"samples\"]\n",
    "    \n",
    "    @property\n",
    "    def explainer(self) -> str:\n",
    "        return self.results_json[\"explainer\"]\n",
    "    \n",
    "    @property\n",
    "    def tests(self) -> list[str]:\n",
    "        return self.results_json[\"tests\"]\n",
    "    \n",
    "    @property\n",
    "    def llo_threshold(self) -> float | None:\n",
    "        return self.results_json.get(\"sentence_similarity_threshold\")\n",
    "    \n",
    "    @property\n",
    "    def time_elapsed(self) -> str:\n",
    "        since_epoch = datetime.datetime.strptime(self.results_json[\"time_elapsed\"], \"%H:%M:%S.%f\")\n",
    "        time_elapsed = datetime.timedelta(\n",
    "            hours=since_epoch.hour,\n",
    "            minutes=since_epoch.minute,\n",
    "            seconds=since_epoch.second,\n",
    "            microseconds=since_epoch.microsecond\n",
    "        )\n",
    "        return time_elapsed\n",
    "    \n",
    "    def __repr__(self):\n",
    "        model = f\"Model: {self.model['full_model_name']} ({self.model['dtype']})\"\n",
    "        tests = f\"Tests: {self.tests}\"\n",
    "        explainer = f\"Explainer: {self.explainer})\"\n",
    "        examples = f\"Examples: {len(self.examples)}\"\n",
    "        args = f\"Args: {self.args}\"\n",
    "        time_elapsed = f\"Time elapsed: {self.time_elapsed}\"\n",
    "        llo_threshold = f\"LLO sim threshold: {self.llo_threshold}\"\n",
    "\n",
    "        return \"\\n\".join((model, tests, explainer, examples, args, time_elapsed, llo_threshold))\n",
    "\n",
    "    def examples_names(self) -> list[str]:\n",
    "        return list(self.examples.keys())\n",
    "\n",
    "    def get_example(self, example_name: str) -> dict:\n",
    "        return self.examples[example_name]\n",
    "    \n",
    "    def get_variable(self, variable):\n",
    "        cc_shap_cot_values = []\n",
    "        for example_name in self.examples_names():\n",
    "            cc_shap_score = self.get_example(example_name)[variable]\n",
    "            cc_shap_cot_values.append(float(cc_shap_score))\n",
    "\n",
    "        return np.array(cc_shap_cot_values)\n",
    "\n",
    "    def describe(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "\n",
    "        print(\"Mean: \", variable_values.mean())\n",
    "        print(\"Min: \", variable_values.min())\n",
    "        print(\"Max: \", variable_values.max())\n",
    "        print(\"Std dev: \", variable_values.std())\n",
    "    \n",
    "    def mean(self, variable):\n",
    "        variable_values = self.get_variable(variable)\n",
    "        return variable_values.mean()\n",
    "\n",
    "    def boxplot(self, variable):\n",
    "        cc_shap_cot_values = self.get_variable(variable)\n",
    "\n",
    "        plt.boxplot(cc_shap_cot_values, orientation=\"horizontal\")\n",
    "        plt.xlim((-1.0, 1.0))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentResults:\n",
    "    def __init__(self, result_files: list[Path]):\n",
    "        self.result_files = result_files\n",
    "    \n",
    "    def load(self):\n",
    "        for file in self.result_files:\n",
    "            result_json = load_json_file(file)\n",
    "            yield ExperimentResult(result_json)\n",
    "    \n",
    "    def compare(self, variable, metric):\n",
    "        variable_values = []\n",
    "        for idx, result_file in enumerate(self.result_files):\n",
    "            result_json = load_json_file(result_file)\n",
    "            variable_value = ExperimentResult(result_json).get_variable(variable)\n",
    "            metric_value = metric(variable_value)\n",
    "            variable_values.append(metric_value)\n",
    "        return variable_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = Path(\"results_json\")\n",
    "\n",
    "COMVE = \"comve\"\n",
    "ESNLI = \"esnli\"\n",
    "DQA = \"disambiguation_qa\"\n",
    "\n",
    "LLAMA2 = \"llama2-7b-chat\"\n",
    "FALCON = \"falcon-7b-chat\"\n",
    "FALCON3 = \"falcon3-7B-chat\"\n",
    "\n",
    "EXPLAINER = \"partition\"\n",
    "\n",
    "comve_llama2 = result_dir / f\"{COMVE}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "esnli_llama2 = result_dir / f\"{ESNLI}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "dqa_llama2 = result_dir / f\"{DQA}_{LLAMA2}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon = result_dir / f\"{COMVE}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "esnli_falcon = result_dir / f\"{ESNLI}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "dqa_falcon = result_dir / f\"{DQA}_{FALCON}_{100}_{EXPLAINER}.json\"\n",
    "\n",
    "comve_falcon3 = result_dir / f\"{COMVE}_{FALCON3}_{100}_{EXPLAINER}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative: [ 1.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.\n",
      "  5.  5.  5.  6.  6.  6.  6.  6.  7.  7.  7.  7.  7.  7.  8.  8.  9.  9.\n",
      "  9.  9. 10. 11. 11. 11. 11. 11. 12. 12. 12. 12. 13. 14. 14. 14. 14. 14.\n",
      " 14. 15. 15. 15. 15. 16. 16. 16. 16. 17. 17. 17. 18. 18. 18. 18. 18. 18.\n",
      " 19. 19. 19. 19. 19. 19. 19. 19. 19. 20. 21. 21. 21. 21. 21. 21. 22. 22.\n",
      " 22. 22. 22. 22. 23. 23. 23. 23. 23. 23.] \n",
      "\n",
      "Differences: [1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Transforms a cumulative array to a array of differences\n",
    "def cumsum_to_differences(cumsum_array):\n",
    "    return np.array([\n",
    "        cumsum_array[idx] - cumsum_array[idx - 1]\n",
    "        if idx != 0 else cumsum_array[idx]\n",
    "        for idx, _ in enumerate(cumsum_array)\n",
    "    ])\n",
    "\n",
    "in_expl_cumsum = ExperimentResult(\n",
    "    load_json_file(comve_llama2)\n",
    ").get_variable(\"atanasova_input_from_expl\")\n",
    "print(\"Cumulative:\", in_expl_cumsum, \"\\n\")\n",
    "print(\"Differences:\", cumsum_to_differences(in_expl_cumsum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: tiiuae/Falcon3-7B-Instruct (torch.float16)\n",
      "Tests: ['atanasova_counterfactual', 'atanasova_input_from_expl', 'cc_shap-posthoc', 'turpin', 'cc_shap-cot']\n",
      "Explainer: {'type': 'shap.explainers.Partition()', 'max_evaluations': 500})\n",
      "Examples: 100\n",
      "Args: Namespace(c_task='comve', model_name='falcon3-7B-chat', number_of_samples=100, explainer_type='partition', max_evaluations=500, classify_pred=False)\n",
      "Time elapsed: 4:59:40.848789\n",
      "LLO sim threshold: None\n"
     ]
    }
   ],
   "source": [
    "print(ExperimentResult(load_json_file(comve_falcon3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_arg(input_str, arg_name) -> str | None:\n",
    "    pattern = rf\"{arg_name}=(?:'([^']*)'|(\\d+))\"\n",
    "    match = re.search(pattern, input_str)\n",
    "    if match:\n",
    "        return match.group(1) or int(match.group(2))\n",
    "    return None\n",
    "\n",
    "experiments = [\n",
    "    comve_llama2,\n",
    "    esnli_llama2,\n",
    "    dqa_llama2,\n",
    "    comve_falcon,\n",
    "    esnli_falcon,\n",
    "    dqa_falcon,\n",
    "    comve_falcon3,\n",
    "]\n",
    "\n",
    "TEST_TO_VARIABLE_NAME = {\n",
    "    \"atanasova_counterfactual\": \"atanasova_counterfact\",\n",
    "    \"atanasova_input_from_expl\": \"atanasova_input_from_expl\",\n",
    "    \"cc_shap-posthoc\": \"cc_shap-posthoc\",\n",
    "    \"turpin\": \"turpin\",\n",
    "    \"cc_shap-cot\": \"cc_shap-cot\",\n",
    "    \"loo-posthoc\": \"loo_cosim_posthoc\",\n",
    "    \"loo-cot\": \"loo_cosim_cot\",\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for experiment in experiments:\n",
    "    experiment = ExperimentResult(load_json_file(experiment))\n",
    "    args = experiment.args\n",
    "    short_model_name = find_arg(args, \"model_name\")\n",
    "    dataset = find_arg(args, \"c_task\")\n",
    "    n_samples = find_arg(args, \"number_of_samples\")\n",
    "\n",
    "    assert n_samples == len(experiment.examples_names()), \"Number of samples from args is different than actual number of samples\"\n",
    "\n",
    "    for test in experiment.tests:\n",
    "        variable_name = TEST_TO_VARIABLE_NAME[test]\n",
    "        test_results = experiment.get_variable(variable_name)\n",
    "\n",
    "        # The \"atanasova_input_from_expl\" keeps a counter and not 0 or 1\n",
    "        # per sample\n",
    "        if test == \"atanasova_input_from_expl\":\n",
    "            test_results = cumsum_to_differences(test_results)\n",
    "\n",
    "        mean = np.mean(test_results)\n",
    "        std = np.std(test_results)\n",
    "        min_val = np.min(test_results)\n",
    "        max_val = np.max(test_results)\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": short_model_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_samples\": n_samples,\n",
    "            \"test\": test,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "\n",
    "experimentsresults_dataframe = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>test</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>-0.0243</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.126175</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.121106</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.200265</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.485386</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama2-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.191141</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>esnli</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.113236</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.493559</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>falcon-7b-chat</td>\n",
       "      <td>disambiguation_qa</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>-0.1663</td>\n",
       "      <td>0.192331</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_counterfactual</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>atanasova_input_from_expl</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-posthoc</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.089853</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>turpin</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>falcon3-7B-chat</td>\n",
       "      <td>comve</td>\n",
       "      <td>100</td>\n",
       "      <td>cc_shap-cot</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.088299</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model            dataset  n_samples                       test  \\\n",
       "0    llama2-7b-chat              comve        100   atanasova_counterfactual   \n",
       "1    llama2-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "2    llama2-7b-chat              comve        100            cc_shap-posthoc   \n",
       "3    llama2-7b-chat              comve        100                     turpin   \n",
       "4    llama2-7b-chat              comve        100                cc_shap-cot   \n",
       "5    llama2-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "6    llama2-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "7    llama2-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "8    llama2-7b-chat              esnli        100                     turpin   \n",
       "9    llama2-7b-chat              esnli        100                cc_shap-cot   \n",
       "10   llama2-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "11   llama2-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "12   llama2-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "13   llama2-7b-chat  disambiguation_qa        100                     turpin   \n",
       "14   llama2-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "15   falcon-7b-chat              comve        100   atanasova_counterfactual   \n",
       "16   falcon-7b-chat              comve        100  atanasova_input_from_expl   \n",
       "17   falcon-7b-chat              comve        100            cc_shap-posthoc   \n",
       "18   falcon-7b-chat              comve        100                     turpin   \n",
       "19   falcon-7b-chat              comve        100                cc_shap-cot   \n",
       "20   falcon-7b-chat              esnli        100   atanasova_counterfactual   \n",
       "21   falcon-7b-chat              esnli        100  atanasova_input_from_expl   \n",
       "22   falcon-7b-chat              esnli        100            cc_shap-posthoc   \n",
       "23   falcon-7b-chat              esnli        100                     turpin   \n",
       "24   falcon-7b-chat              esnli        100                cc_shap-cot   \n",
       "25   falcon-7b-chat  disambiguation_qa        100   atanasova_counterfactual   \n",
       "26   falcon-7b-chat  disambiguation_qa        100  atanasova_input_from_expl   \n",
       "27   falcon-7b-chat  disambiguation_qa        100            cc_shap-posthoc   \n",
       "28   falcon-7b-chat  disambiguation_qa        100                     turpin   \n",
       "29   falcon-7b-chat  disambiguation_qa        100                cc_shap-cot   \n",
       "30  falcon3-7B-chat              comve        100   atanasova_counterfactual   \n",
       "31  falcon3-7B-chat              comve        100  atanasova_input_from_expl   \n",
       "32  falcon3-7B-chat              comve        100            cc_shap-posthoc   \n",
       "33  falcon3-7B-chat              comve        100                     turpin   \n",
       "34  falcon3-7B-chat              comve        100                cc_shap-cot   \n",
       "\n",
       "      mean       std   min   max  \n",
       "0   0.8600  0.346987  0.00  1.00  \n",
       "1   0.2300  0.420833  0.00  1.00  \n",
       "2  -0.0243  0.105245 -0.24  0.37  \n",
       "3   0.6000  0.489898  0.00  1.00  \n",
       "4  -0.1027  0.106910 -0.35  0.33  \n",
       "5   0.5200  0.499600  0.00  1.00  \n",
       "6   0.0000  0.000000  0.00  0.00  \n",
       "7   0.1241  0.126175 -0.17  0.39  \n",
       "8   0.3100  0.462493  0.00  1.00  \n",
       "9   0.0812  0.121106 -0.24  0.34  \n",
       "10  0.7600  0.427083  0.00  1.00  \n",
       "11  0.0000  0.000000  0.00  0.00  \n",
       "12  0.0800  0.200265 -0.32  0.52  \n",
       "13  0.3800  0.485386  0.00  1.00  \n",
       "14  0.0605  0.191141 -0.43  0.62  \n",
       "15  0.2300  0.420833  0.00  1.00  \n",
       "16  0.0000  0.000000  0.00  0.00  \n",
       "17  0.1232  0.082667 -0.06  0.33  \n",
       "18  0.5700  0.495076  0.00  1.00  \n",
       "19  0.0436  0.102747 -0.33  0.53  \n",
       "20  0.3100  0.462493  0.00  1.00  \n",
       "21  0.0000  0.000000  0.00  0.00  \n",
       "22  0.1642  0.079501 -0.02  0.43  \n",
       "23  0.0800  0.271293  0.00  1.00  \n",
       "24  0.0658  0.113236 -0.27  0.28  \n",
       "25  0.4200  0.493559  0.00  1.00  \n",
       "26  0.0000  0.000000  0.00  0.00  \n",
       "27  0.0821  0.094491 -0.16  0.36  \n",
       "28  0.4000  0.489898  0.00  1.00  \n",
       "29 -0.1663  0.192331 -0.47  0.51  \n",
       "30  0.8500  0.357071  0.00  1.00  \n",
       "31  0.4900  0.499900  0.00  1.00  \n",
       "32  0.3462  0.089853  0.15  0.62  \n",
       "33  0.9100  0.286182  0.00  1.00  \n",
       "34  0.5085  0.088299  0.29  0.77  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experimentsresults_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLO Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/rick/.cache/huggingface/datasets/sentence-transformers___parquet/sentence-transformers--stsb-3f9e65f9f13e8bdf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba2179f21ed4c37a7ad053518a819e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sts_dataset = load_dataset(\"sentence-transformers/stsb\")\n",
    "train_sts_dataset = sts_dataset.get(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plane is taking off.\n",
      "An air plane is taking off.\n",
      "Score: 1.0, Predicted similarity: 0.9393033981323242 \n",
      "\n",
      "A man is playing a large flute.\n",
      "A man is playing a flute.\n",
      "Score: 0.76, Predicted similarity: 0.9020318388938904 \n",
      "\n",
      "A man is spreading shreded cheese on a pizza.\n",
      "A man is spreading shredded cheese on an uncooked pizza.\n",
      "Score: 0.76, Predicted similarity: 0.8920011520385742 \n",
      "\n",
      "Three men are playing chess.\n",
      "Two men are playing chess.\n",
      "Score: 0.52, Predicted similarity: 0.7945607304573059 \n",
      "\n",
      "A man is playing the cello.\n",
      "A man seated is playing the cello.\n",
      "Score: 0.85, Predicted similarity: 0.9286526441574097 \n",
      "\n",
      "Some men are fighting.\n",
      "Two men are fighting.\n",
      "Score: 0.85, Predicted similarity: 0.8919877409934998 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence_pair_similarity in enumerate(train_sts_dataset):\n",
    "    sentence_1 = sentence_pair_similarity[\"sentence1\"]\n",
    "    sentence_2 = sentence_pair_similarity[\"sentence2\"]\n",
    "    pair = [sentence_1, sentence_2]\n",
    "    encoded_sentences = encoder.encode(pair)\n",
    "    similarity = cosine_similarity(encoded_sentences[0:1], encoded_sentences[1:2])[0][0]\n",
    "    print(\"\\n\".join((\n",
    "        sentence_1,\n",
    "        sentence_2,\n",
    "        f\"Score: {sentence_pair_similarity['score']}, Predicted similarity: {similarity}\"\n",
    "    )), \"\\n\")\n",
    "\n",
    "    if idx == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different LLO Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "llo_results = Path(\"results_LLO_threshold\")\n",
    "\n",
    "threshold_files = llo_results.glob(\"*.json\")\n",
    "\n",
    "llo_rows = []\n",
    "for experiment in threshold_files:\n",
    "    experiment = ExperimentResult(load_json_file(experiment))\n",
    "    args = experiment.args\n",
    "    short_model_name = find_arg(args, \"model_name\")\n",
    "    dataset = find_arg(args, \"c_task\")\n",
    "    n_samples = find_arg(args, \"number_of_samples\")\n",
    "    llo_threshold = experiment.llo_threshold\n",
    "\n",
    "    assert n_samples == len(experiment.examples_names()), \"Number of samples from args is different than actual number of samples\"\n",
    "\n",
    "    for test in experiment.tests:\n",
    "        variable_name = TEST_TO_VARIABLE_NAME[test]\n",
    "        test_results = experiment.get_variable(variable_name)\n",
    "\n",
    "        # The \"atanasova_input_from_expl\" keeps a counter and not 0 or 1\n",
    "        # per sample\n",
    "        if test == \"atanasova_input_from_expl\":\n",
    "            test_results = cumsum_to_differences(test_results)\n",
    "\n",
    "        mean = np.mean(test_results)\n",
    "        std = np.std(test_results)\n",
    "        min_val = np.min(test_results)\n",
    "        max_val = np.max(test_results)\n",
    "\n",
    "        new_row = {\n",
    "            \"Model\": short_model_name,\n",
    "            \"dataset\": dataset,\n",
    "            \"n_samples\": n_samples,\n",
    "            \"llo_threshold\": llo_threshold,\n",
    "            \"test\": test,\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": min_val,\n",
    "            \"max\": max_val,\n",
    "        }\n",
    "        llo_rows.append(new_row)\n",
    "\n",
    "llo_results_dataframe = pd.DataFrame(llo_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>llo_threshold</th>\n",
       "      <th>test</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.136323</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>0.069685</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.178989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.172534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.60</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.172145</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>comve</td>\n",
       "      <td>50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>loo-posthoc</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model dataset  n_samples  llo_threshold         test    mean       std  \\\n",
       "14  gpt2   comve          1           0.10  loo-posthoc  0.0000  0.000000   \n",
       "20  gpt2   comve          1           0.20  loo-posthoc  0.0000  0.000000   \n",
       "0   gpt2   comve          1           0.30  loo-posthoc  0.0000  0.000000   \n",
       "11  gpt2   comve          1           0.40  loo-posthoc  0.0000  0.000000   \n",
       "21  gpt2   comve          1           0.50  loo-posthoc  0.0000  0.000000   \n",
       "7   gpt2   comve          1           0.60  loo-posthoc  0.0000  0.000000   \n",
       "12  gpt2   comve          1           0.70  loo-posthoc  0.0000  0.000000   \n",
       "6   gpt2   comve          1           0.80  loo-posthoc  0.0000  0.000000   \n",
       "10  gpt2   comve          1           0.90  loo-posthoc  0.2500  0.000000   \n",
       "17  gpt2   comve          1           0.99  loo-posthoc  0.1800  0.000000   \n",
       "9   gpt2   comve          5           0.20  loo-posthoc  0.0000  0.000000   \n",
       "16  gpt2   comve          5           0.40  loo-posthoc  0.0000  0.000000   \n",
       "2   gpt2   comve          5           0.50  loo-posthoc  0.0000  0.000000   \n",
       "1   gpt2   comve          5           0.60  loo-posthoc  0.0300  0.060000   \n",
       "19  gpt2   comve          5           0.80  loo-posthoc  0.1340  0.136323   \n",
       "3   gpt2   comve          5           1.00  loo-posthoc  0.2980  0.069685   \n",
       "18  gpt2   comve         50           0.20  loo-posthoc  0.0100  0.070000   \n",
       "15  gpt2   comve         50           0.40  loo-posthoc  0.0730  0.178989   \n",
       "5   gpt2   comve         50           0.50  loo-posthoc  0.0860  0.172534   \n",
       "13  gpt2   comve         50           0.60  loo-posthoc  0.0978  0.176298   \n",
       "4   gpt2   comve         50           0.80  loo-posthoc  0.1702  0.172145   \n",
       "8   gpt2   comve         50           1.00  loo-posthoc  0.2724  0.058431   \n",
       "\n",
       "     min   max  \n",
       "14  0.00  0.00  \n",
       "20  0.00  0.00  \n",
       "0   0.00  0.00  \n",
       "11  0.00  0.00  \n",
       "21  0.00  0.00  \n",
       "7   0.00  0.00  \n",
       "12  0.00  0.00  \n",
       "6   0.00  0.00  \n",
       "10  0.25  0.25  \n",
       "17  0.18  0.18  \n",
       "9   0.00  0.00  \n",
       "16  0.00  0.00  \n",
       "2   0.00  0.00  \n",
       "1   0.00  0.15  \n",
       "19  0.00  0.37  \n",
       "3   0.23  0.42  \n",
       "18  0.00  0.50  \n",
       "15  0.00  0.71  \n",
       "5   0.00  0.58  \n",
       "13  0.00  0.71  \n",
       "4   0.00  0.55  \n",
       "8   0.16  0.43  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(llo_results_dataframe.sort_values([\"n_samples\", \"llo_threshold\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
